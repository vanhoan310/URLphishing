{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51996577-859a-466e-a40f-b60f6a51a8d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27eb25f1-dbc1-4bfc-9deb-da49f7c72c35",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from utils import run_ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5ac7c73-a600-48e9-8931-3afa1679e506",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install tldextract\n",
    "# !pip install torch_geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4b90b7a-8d1a-4472-889c-bc87ef4a9706",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_dir = \"data/URLdatasetX2_1.csv\"\n",
    "df = pd.read_csv(data_dir,index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de4c208e-0060-4bd7-81c9-f013a1b0fdec",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2802, 2),\n",
       "                                           url        type\n",
       " 0       http://www.crestonwood.com/router.php  legitimate\n",
       " 1  http://vamoaestudiarmedicina.blogspot.com/  legitimate)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape, df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8cde64b2-2039-4c86-9c75-dffd2289622e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# smalldata = df.sample(n = 20000, random_state=1)\n",
    "smalldata = df.sample(n = 2000, random_state=1) # take random 300 samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "40045bbf-06bf-491e-8363-633d44c31be6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get labels of urls\n",
    "labels = smalldata.iloc[:,-1].values\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "labels = label_encoder.fit_transform(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa0a837d-63e3-40cf-afc9-9593072d34e4",
   "metadata": {},
   "source": [
    "### Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3cd8d0e0-af10-42b5-9bd9-bced95415a22",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils import extract_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "155e525e-f2fc-49d2-8be2-3b64ea9b67b4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'domain': 'www.example.com', 'num_subdomains': 2, 'contains_ip': 0, 'path_length': 20, 'num_path_segments': 3, 'uses_https': 0, 'file_extension': 'html', 'count_special_characters': 11, 'count_non_alphanumeric_characters': 11, 'TLD': 'com', 'count_obfuscated_characters': 0, 'letter_ratio_in_url': 0.7380952380952381, 'digit_ratio_in_url': 0.0, 'count_equals_in_url': 2, 'NoOfAmpersandInURL': 0, 'CharContinuationRate': 0.11904761904761904, 'ratio_obfuscated_characters': 0.0, 'NoOfQMarkInURL': 0}\n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "url = \"http://www.example.com/path/to/==file.html\"\n",
    "url_features = extract_features(url)\n",
    "print(url_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2377259d-5b19-4f0f-8758-96b1b330d117",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print(url_features.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "66cae4c3-a178-435c-9830-a4f5fd8fdc06",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get numerical and catergorical features\n",
    "phish_url = []\n",
    "for link in list(smalldata.iloc[:,0]):\n",
    "    url_features = extract_features(link)\n",
    "    phish_url.append(list(url_features.values())[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "664a11ec-0a42-4a01-91f2-208aa5796b64",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "phish_url_df = pd.DataFrame(phish_url, columns = list(url_features.keys())[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "383162e7-d058-471e-b921-d2e983efe066",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# phish_url_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aabba33a-d06a-4a3f-b021-ff8cbde0088c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "phish_url_df.iloc[:,5] = pd.Categorical(phish_url_df.iloc[:,5]).codes\n",
    "phish_url_df.iloc[:,8] = pd.Categorical(phish_url_df.iloc[:,8]).codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1cc59152-00c2-41ec-acf5-afeae474f39e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_subdomains</th>\n",
       "      <th>contains_ip</th>\n",
       "      <th>path_length</th>\n",
       "      <th>num_path_segments</th>\n",
       "      <th>uses_https</th>\n",
       "      <th>file_extension</th>\n",
       "      <th>count_special_characters</th>\n",
       "      <th>count_non_alphanumeric_characters</th>\n",
       "      <th>TLD</th>\n",
       "      <th>count_obfuscated_characters</th>\n",
       "      <th>letter_ratio_in_url</th>\n",
       "      <th>digit_ratio_in_url</th>\n",
       "      <th>count_equals_in_url</th>\n",
       "      <th>NoOfAmpersandInURL</th>\n",
       "      <th>CharContinuationRate</th>\n",
       "      <th>ratio_obfuscated_characters</th>\n",
       "      <th>NoOfQMarkInURL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0.569231</td>\n",
       "      <td>0.292308</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   num_subdomains  contains_ip  path_length  num_path_segments  uses_https  \\\n",
       "0               2            0           40                  3           1   \n",
       "1               2            0            1                  1           1   \n",
       "\n",
       "  file_extension  count_special_characters  count_non_alphanumeric_characters  \\\n",
       "0              0                         9                                  9   \n",
       "1              0                         6                                  6   \n",
       "\n",
       "  TLD  count_obfuscated_characters  letter_ratio_in_url  digit_ratio_in_url  \\\n",
       "0  37                            0             0.569231            0.292308   \n",
       "1  37                            0             0.785714            0.000000   \n",
       "\n",
       "   count_equals_in_url  NoOfAmpersandInURL  CharContinuationRate  \\\n",
       "0                    0                   0              0.076923   \n",
       "1                    0                   0              0.142857   \n",
       "\n",
       "   ratio_obfuscated_characters  NoOfQMarkInURL  \n",
       "0                          0.0               0  \n",
       "1                          0.0               0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phish_url_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "503ed86a-9489-487f-8054-8c0d4653da36",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run:  0 , fold:  0\n",
      "Train freq:  [1179, 421]\n",
      "kNN, LightGBM, Run:  0 , fold:  1\n",
      "Train freq:  [1165, 435]\n",
      "kNN, LightGBM, Run:  0 , fold:  2\n",
      "Train freq:  [1180, 420]\n",
      "kNN, LightGBM, Run:  0 , fold:  3\n",
      "Train freq:  [1166, 434]\n",
      "kNN, LightGBM, Run:  0 , fold:  4\n",
      "Train freq:  [1158, 442]\n",
      "kNN, LightGBM, ['kNN', 'LightGBM']\n",
      "[0.68 0.87]\n"
     ]
    }
   ],
   "source": [
    "# test on URLs features\n",
    "run_ML(phish_url_df, labels, \"URLdatasetX2\", \"manual\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "32a1c51d-a596-43bf-a2db-0385d1f82953",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run:  0 , fold:  0\n",
      "Train freq:  [1179, 421]\n",
      "kNN, LightGBM, Run:  0 , fold:  1\n",
      "Train freq:  [1165, 435]\n",
      "kNN, LightGBM, Run:  0 , fold:  2\n",
      "Train freq:  [1180, 420]\n",
      "kNN, LightGBM, Run:  0 , fold:  3\n",
      "Train freq:  [1166, 434]\n",
      "kNN, LightGBM, Run:  0 , fold:  4\n",
      "Train freq:  [1158, 442]\n",
      "kNN, LightGBM, ['kNN', 'LightGBM']\n",
      "[0.69 0.83]\n"
     ]
    }
   ],
   "source": [
    "## test on numerical URLs features\n",
    "from utils import extract_numerical_features\n",
    "phish_url = []\n",
    "for link in list(smalldata.iloc[:,0]):\n",
    "    url_features = extract_numerical_features(link)\n",
    "    phish_url.append(list(url_features.values()))\n",
    "run_ML(np.array(phish_url), labels, \"URLdatasetX2\", \"manual_numerical\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0197c624-004a-4488-b964-6614d4d87d30",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Extract graph features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "41e1310b-4dbf-4d02-9bff-bd239f122c99",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from requests.exceptions import ConnectionError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "915bbff4-e3dd-41c1-ab35-521e6157ab38",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# return root and hyperlinks features\n",
    "def get_graph_features(idx):\n",
    "    url = smalldata.iloc[idx,0]\n",
    "    root_feature = extract_numerical_features(url) # dict\n",
    "    hyperlink_data = [list(root_feature.values())]\n",
    "    try:    \n",
    "        # find all hyperlinks\n",
    "        reqs = requests.get(url)\n",
    "        soup = BeautifulSoup(reqs.text, 'html.parser')\n",
    "        urls = []\n",
    "        count = 0;\n",
    "        for link in soup.find_all('a'):\n",
    "            # print(link.get('href'))\n",
    "            weblink = link.get('href')\n",
    "            if (weblink is not None) and ('http' in weblink):\n",
    "                urls.append(weblink)\n",
    "            count += 1\n",
    "            if count > 50:\n",
    "                break\n",
    "        # extract numerical features in from hyperlinks\n",
    "        if len(urls) > 0:\n",
    "            for link in urls:\n",
    "                try:\n",
    "                    url_features = extract_numerical_features(link)\n",
    "                    datalinkssss = list(url_features.values())\n",
    "                except ValueError as ve:\n",
    "                    datalinkssss = list(np.zeros(15))\n",
    "                hyperlink_data.append(datalinkssss)\n",
    "        else:\n",
    "            hyperlink_data.append(list(np.zeros(15)))\n",
    "    \n",
    "    except ConnectionError as e:\n",
    "        # print(\"No rep\", end = ',')\n",
    "        hyperlink_data.append(list(np.zeros(15)))\n",
    "    return (idx,  hyperlink_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "56636bab-16b8-4143-862e-68d406c4b45d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_test_samples = 200 # how many link we want to test\n",
    "from joblib import Parallel, delayed\n",
    "results = Parallel(n_jobs=8)(delayed(get_graph_features)(i) for i in range(n_test_samples)) # test on 100 links"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4ab5d3-ae71-4346-9d73-b03f0646a7fa",
   "metadata": {},
   "source": [
    "## PyG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c19af397-21f9-4f0f-a743-1a71fb5fa8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Transfer data object to GPU.\n",
    "# device = torch.device('cuda')\n",
    "# data = data.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "181472cb-4e72-48dd-b84b-8f7e6439ef71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data, Dataset\n",
    "\n",
    "class GraphClassificationDataset(Dataset):\n",
    "    def __init__(self, graphs):\n",
    "        self.graphs = graphs\n",
    "        # self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.graphs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        graph = self.graphs[idx]\n",
    "        # label = self.labels[idx]\n",
    "        return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2f837f2d-6bdd-406c-827f-5fc26f527c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume you have a list of graphs represented as Data objects and a corresponding list of labels\n",
    "# Only take the url with more than 4 hyperlinks\n",
    "graphs = []\n",
    "for i in range(len(results)):\n",
    "    idx, graph_feature = results[i]\n",
    "    n_hyperlinks = len(graph_feature)-1\n",
    "    child_id = [i+1 for i in range(n_hyperlinks)]\n",
    "    source_id = list(np.zeros(n_hyperlinks).astype(int))\n",
    "    edge_index = torch.tensor([source_id + child_id,\n",
    "                               child_id + source_id], dtype=torch.long)\n",
    "    x = torch.tensor(graph_feature, dtype=torch.float)\n",
    "    y = torch.tensor([labels[idx]], dtype=torch.int64)\n",
    "    data = Data(x=x, edge_index=edge_index, y = y)\n",
    "    if n_hyperlinks > 5:\n",
    "        graphs.append(data)\n",
    "   \n",
    "# Create a dataset instance\n",
    "dataset = GraphClassificationDataset(graphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "44a3a5ee-7d6e-412c-8ec3-7a653bbbb72f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[18, 15], edge_index=[2, 34], y=[1])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6dc5a361-8c19-48a4-a651-f46ca40ffdbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset: GraphClassificationDataset(94):\n",
      "====================\n",
      "Number of graphs: 94\n",
      "Number of features: 15\n",
      "Number of classes: 2\n"
     ]
    }
   ],
   "source": [
    "print()\n",
    "print(f'Dataset: {dataset}:')\n",
    "print('====================')\n",
    "print(f'Number of graphs: {len(dataset)}')\n",
    "print(f'Number of features: {dataset.num_features}')\n",
    "print(f'Number of classes: {dataset.num_classes}')\n",
    "\n",
    "data = dataset[0]  # Get the first graph object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7662911c-f72a-470c-9e57-5ac1a504f2a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = dataset.shuffle()\n",
    "n_samples = len(dataset)\n",
    "train_dataset = dataset[:int(0.8*n_samples)]\n",
    "test_dataset = dataset[int(0.8*n_samples):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5b8c74ac-9ca9-498f-b5dc-ee77ab28f254",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75, 19)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset), len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7e273ba5-2d67-4b83-9ce4-6e8f11d45c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5f975f01-7eb2-4b3e-9bd7-b8c897785e90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN(\n",
      "  (conv1): GCNConv(15, 64)\n",
      "  (conv2): GCNConv(64, 64)\n",
      "  (conv3): GCNConv(64, 64)\n",
      "  (lin): Linear(in_features=64, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from torch.nn import Linear\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.nn import global_mean_pool\n",
    "\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super(GCN, self).__init__()\n",
    "        torch.manual_seed(12345)\n",
    "        self.conv1 = GCNConv(dataset.num_node_features, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.conv3 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.lin = Linear(hidden_channels, dataset.num_classes)\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        # 1. Obtain node embeddings \n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = self.conv3(x, edge_index)\n",
    "\n",
    "        # 2. Readout layer\n",
    "        x = global_mean_pool(x, batch)  # [batch_size, hidden_channels]\n",
    "\n",
    "        # 3. Apply a final classifier\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.lin(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "model = GCN(hidden_channels=64)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bd41cc6b-7c71-4d42-9b24-5419f05f98c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Train Acc: 0.9333, Test Acc: 0.8947\n",
      "Epoch: 002, Train Acc: 0.9333, Test Acc: 0.8947\n",
      "Epoch: 003, Train Acc: 0.9333, Test Acc: 0.8947\n",
      "Epoch: 004, Train Acc: 0.9333, Test Acc: 0.8947\n",
      "Epoch: 005, Train Acc: 0.9333, Test Acc: 0.8947\n",
      "Epoch: 006, Train Acc: 0.9467, Test Acc: 0.8947\n",
      "Epoch: 007, Train Acc: 0.9333, Test Acc: 0.8947\n",
      "Epoch: 008, Train Acc: 0.9333, Test Acc: 0.8947\n",
      "Epoch: 009, Train Acc: 0.9467, Test Acc: 0.8947\n"
     ]
    }
   ],
   "source": [
    "model = GCN(hidden_channels=64)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "\n",
    "    for data in train_loader:  # Iterate in batches over the training dataset.\n",
    "         out = model(data.x, data.edge_index, data.batch)  # Perform a single forward pass.\n",
    "         loss = criterion(out, data.y)  # Compute the loss.\n",
    "         loss.backward()  # Derive gradients.\n",
    "         optimizer.step()  # Update parameters based on gradients.\n",
    "         optimizer.zero_grad()  # Clear gradients.\n",
    "\n",
    "def test(loader):\n",
    "     model.eval()\n",
    "\n",
    "     correct = 0\n",
    "     for data in loader:  # Iterate in batches over the training/test dataset.\n",
    "         out = model(data.x, data.edge_index, data.batch)  \n",
    "         pred = out.argmax(dim=1)  # Use the class with highest probability.\n",
    "         correct += int((pred == data.y).sum())  # Check against ground-truth labels.\n",
    "     return correct / len(loader.dataset)  # Derive ratio of correct predictions.\n",
    "\n",
    "\n",
    "for epoch in range(1, 10):\n",
    "    train()\n",
    "    train_acc = test(train_loader)\n",
    "    test_acc = test(test_loader)\n",
    "    print(f'Epoch: {epoch:03d}, Train Acc: {train_acc:.4f}, Test Acc: {test_acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb46af3-23a3-4c2b-a73a-496e34bdd7d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python py38",
   "language": "python",
   "name": "py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
