{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hàm trích xuất đặc trưng từ url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'TLD': 46, 'URLLength': 27, 'IsDomainIP': 0, 'NoOfSubDomain': 3, 'NoOfObfuscatedChar': 0, 'IsHTTPS': 1, 'NoOfDegitsInURL': 0, 'NoOfEqualsInURL': 0, 'NoOfQMarkInURL': 0, 'NoOfAmpersandInURL': 0}\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from urllib.parse import urlparse\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin\n",
    "\n",
    "\n",
    "def extract_features(url):\n",
    "    try:\n",
    "        parsed_url = urlparse(url)\n",
    "        \n",
    "        # TLD\n",
    "        tld = parsed_url.netloc.split('.')[-1]\n",
    "        \n",
    "        # Feature hashing cho TLD\n",
    "        tld_hashed = feature_hash(tld)\n",
    "        \n",
    "        # URL Length\n",
    "        url_length = len(url)\n",
    "        \n",
    "        # Is Domain IP\n",
    "        is_domain_ip = 1 if parsed_url.netloc.replace('.', '').isdigit() else 0\n",
    "        \n",
    "        # Number of Subdomains\n",
    "        subdomains = parsed_url.netloc.split('.')\n",
    "        num_subdomains = len(subdomains)-2\n",
    "        \n",
    "        # Number of Obfuscated Characters\n",
    "        num_obfuscated_chars = sum([url.count(char) for char in ['@', '-', '_', '~']])\n",
    "        \n",
    "        # Is HTTPS\n",
    "        is_https = 1 if parsed_url.scheme == 'https' else 0\n",
    "        \n",
    "        # Number of Digits in URL\n",
    "        num_digits = sum(c.isdigit() for c in url)\n",
    "        \n",
    "        # Number of Equals in URL\n",
    "        num_equals = url.count('=')\n",
    "        \n",
    "        # Number of Question Marks in URL\n",
    "        num_qmark = url.count('?')\n",
    "        \n",
    "        # Number of Ampersands in URL\n",
    "        num_ampersand = url.count('&')\n",
    "    \n",
    "        return {\n",
    "            'TLD': tld_hashed,\n",
    "            'URLLength': url_length,\n",
    "            'IsDomainIP': is_domain_ip,\n",
    "            'NoOfSubDomain': num_subdomains,\n",
    "            'NoOfObfuscatedChar': num_obfuscated_chars,\n",
    "            'IsHTTPS': is_https,\n",
    "            'NoOfDegitsInURL': num_digits,\n",
    "            'NoOfEqualsInURL': num_equals,\n",
    "            'NoOfQMarkInURL': num_qmark,\n",
    "            'NoOfAmpersandInURL': num_ampersand\n",
    "        }\n",
    "    except:\n",
    "        print(\"Lỗi khi trichs xuất đặc trưng\")\n",
    "\n",
    "def feature_hash(value, num_features=100):\n",
    "    # Sử dụng hàm hash để ánh xạ giá trị vào một phạm vi num_features\n",
    "    return hash(value) % num_features\n",
    "# Example URL to test\n",
    "#test_url = \"mailto://www.arara.org\"\n",
    "test_url = \"https://www.ci.boerne.tx.us\"\n",
    "\n",
    "# Extract features from the test URL\n",
    "print(extract_features(test_url))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hàm trích xuất hyperlinks từ url, giới hạn max = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin\n",
    "from requests.exceptions import ConnectionError\n",
    "\n",
    "def extract_hyperlinks(url):\n",
    "    try:\n",
    "        # Sử dụng requests để lấy nội dung của trang web\n",
    "        response = requests.get(url)\n",
    "        \n",
    "        # Kiểm tra xem request có thành công không\n",
    "        if response.status_code != 200:\n",
    "            return []  # Trả về một danh sách rỗng nếu request không thành công\n",
    "        \n",
    "        # Sử dụng BeautifulSoup để phân tích cú pháp HTML\n",
    "        soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "        \n",
    "        # Tìm tất cả các thẻ <a> trong trang web\n",
    "        links = []\n",
    "        max_links = 20\n",
    "        count = 0\n",
    "        for link in soup.find_all('a'):\n",
    "            href = link.get('href')\n",
    "            if href:  # Đảm bảo thuộc tính href tồn tại\n",
    "                # Đưa đường dẫn tương đối thành đường dẫn tuyệt đối\n",
    "                absolute_url = urljoin(url, href)\n",
    "                # Thêm liên kết vào danh sách nếu nó không trùng lặp\n",
    "                if absolute_url not in links and count < max_links:\n",
    "                    links.append(absolute_url)\n",
    "                    count += 1\n",
    "                elif count >= max_links:\n",
    "                    break  # Dừng vòng lặp nếu số lượng link vượt quá 20\n",
    "        \n",
    "        return links\n",
    "    except:\n",
    "        print(\"lỗi khi trích xuất hyperlinks\", end = ',')\n",
    "extract_hyperlinks ('http://www.expoglobalservice.com')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hàm biểu diễn mỗi url thành 1 đồ thị"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rollie/anaconda3/envs/myenv/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([21, 10])\n",
      "torch.Size([2, 20])\n",
      "tensor([[46., 27.,  0.,  3.,  0.,  1.,  0.,  0.,  0.,  0.],\n",
      "        [46., 66.,  0.,  3.,  4.,  1., 20.,  0.,  0.,  0.],\n",
      "        [46., 28.,  0.,  3.,  0.,  1.,  0.,  0.,  0.,  0.],\n",
      "        [46., 42.,  0.,  3.,  0.,  1.,  0.,  0.,  0.,  0.],\n",
      "        [46., 41.,  0.,  3.,  0.,  1.,  2.,  0.,  0.,  0.],\n",
      "        [46., 39.,  0.,  3.,  0.,  1.,  1.,  0.,  0.,  0.],\n",
      "        [46., 46.,  0.,  3.,  1.,  1.,  3.,  0.,  0.,  0.],\n",
      "        [46., 42.,  0.,  3.,  0.,  1.,  2.,  0.,  0.,  0.],\n",
      "        [46., 41.,  0.,  3.,  2.,  1.,  3.,  0.,  0.,  0.],\n",
      "        [46., 41.,  0.,  3.,  0.,  1.,  3.,  0.,  0.,  0.],\n",
      "        [29., 43.,  0.,  1.,  0.,  1.,  0.,  0.,  0.,  0.],\n",
      "        [46., 53.,  0.,  3.,  1.,  1.,  4.,  0.,  0.,  0.],\n",
      "        [46., 42.,  0.,  3.,  0.,  1.,  4.,  0.,  0.,  0.],\n",
      "        [29., 41.,  0.,  1.,  0.,  1.,  0.,  0.,  0.,  0.],\n",
      "        [46., 47.,  0.,  3.,  1.,  1.,  3.,  0.,  0.,  0.],\n",
      "        [46., 46.,  0.,  3.,  1.,  1.,  4.,  0.,  0.,  0.],\n",
      "        [46., 51.,  0.,  3.,  2.,  1.,  2.,  0.,  0.,  0.],\n",
      "        [46., 35.,  0.,  3.,  0.,  1.,  2.,  0.,  0.,  0.],\n",
      "        [46., 40.,  0.,  3.,  0.,  1.,  4.,  0.,  0.,  0.],\n",
      "        [46., 49.,  0.,  3.,  1.,  1.,  4.,  0.,  0.,  0.],\n",
      "        [46., 37.,  0.,  3.,  0.,  1.,  2.,  0.,  0.,  0.]])\n",
      "tensor([[ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18,\n",
      "         19, 20]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "def url_to_graph(url):\n",
    "    try:\n",
    "    \n",
    "        features = extract_features(url)\n",
    "        \n",
    "        # Tạo danh sách các nút và các đặc trưng tương ứng\n",
    "        nodes = [url]\n",
    "        node_features = [list(features.values())]\n",
    "        \n",
    "        # Trích xuất liên kết từ URL và thêm vào danh sách các nút và đặc trưng\n",
    "        hyperlinks = extract_hyperlinks(url)\n",
    "        if len(hyperlinks) != 0: \n",
    "            for link in hyperlinks:\n",
    "                nodes.append(link)\n",
    "                features_link = extract_features(link)\n",
    "                node_features.append(list(features_link.values()))\n",
    "        \n",
    "        # Tạo tensor chứa các đặc trưng của các nút\n",
    "        x = torch.tensor(node_features, dtype=torch.float)\n",
    "\n",
    "       # import torch\n",
    "\n",
    "        # Giả sử x là tensor ban đầu\n",
    "        # x = ... (tensor có kích thước khác mong muốn)\n",
    "\n",
    "        # Kích thước mong muốn\n",
    "        desired_size = [21, 10]\n",
    "\n",
    "        # Nếu tensor x có kích thước lớn hơn kích thước mong muốn, bạn có thể cắt bớt hàng\n",
    "        if x.size(0) > desired_size[0]:\n",
    "            x = x[:desired_size[0], :]\n",
    "\n",
    "        # Nếu tensor x có kích thước nhỏ hơn kích thước mong muốn, bạn có thể thêm hàng padding\n",
    "        elif x.size(0) < desired_size[0]:\n",
    "            # Tạo tensor padding với giá trị 0 có kích thước phù hợp\n",
    "            padding_rows = desired_size[0] - x.size(0)\n",
    "            padding = torch.zeros(padding_rows, x.size(1))\n",
    "            # Thêm tensor padding vào cuối tensor x\n",
    "            x = torch.cat((x, padding), dim=0)\n",
    "\n",
    "        # Kiểm tra kích thước mới của tensor x\n",
    "        print(x.size())  # Kết quả: torch.Size([21, 10])\n",
    "\n",
    "        \n",
    "        # Chuyển đổi cạnh thành danh sách cạnh (dạng (src, dst))\n",
    "        edge_index = []\n",
    "        \n",
    "        # Thêm các cạnh từ URL gốc đến các liên kết mới\n",
    "        url_index = nodes.index(url)\n",
    "        if len(hyperlinks) !=0:\n",
    "            for i, link in enumerate(hyperlinks):\n",
    "                link_index = nodes.index(link)\n",
    "                edge_index.append([url_index, link_index])\n",
    "\n",
    "        if len(edge_index) !=0:\n",
    "            edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
    "\n",
    "\n",
    "        # Desired size (2, 20)\n",
    "            new_size = (2, 20)\n",
    "\n",
    "        # Initialize a tensor filled with -1 as padding value\n",
    "            padded_edge_index = torch.full(new_size, -1, dtype=torch.long)\n",
    "\n",
    "        # Copy data from edge_index to padded_edge_index\n",
    "            padded_edge_index[:, :edge_index.size(1)] = edge_index\n",
    "\n",
    "        # padded_edge_index is now padded to the size (2, 20)\n",
    "            edge_index = padded_edge_index\n",
    "\n",
    "            print(edge_index.size())\n",
    "        else:\n",
    "            edge_index = torch.zeros((2, 20), dtype=torch.long)\n",
    "\n",
    "        # Tạo đối tượng Data từ các đặc trưng và cạnh\n",
    "        data = Data(x=x, edge_index=edge_index)\n",
    "\n",
    "        return data\n",
    "    except:\n",
    "        print(\"Lỗi khi url to graph\")\n",
    "        print(url)\n",
    "\n",
    "# Example URL\n",
    "url = \"https://www.ci.boerne.tx.us\"\n",
    "\n",
    "# Convert URL to Graph\n",
    "graph_data = url_to_graph(url)\n",
    "print(graph_data.x)\n",
    "print(graph_data.edge_index)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tạo tập train_loader và test_loader, chuẩn bị cho train mô hình GNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.ci.boerne.tx.us\n",
      "torch.Size([21, 10])\n",
      "torch.Size([2, 20])\n",
      "tensor([[46., 27.,  0.,  3.,  0.,  1.,  0.,  0.,  0.,  0.],\n",
      "        [46., 66.,  0.,  3.,  4.,  1., 20.,  0.,  0.,  0.],\n",
      "        [46., 28.,  0.,  3.,  0.,  1.,  0.,  0.,  0.,  0.],\n",
      "        [46., 42.,  0.,  3.,  0.,  1.,  0.,  0.,  0.,  0.],\n",
      "        [46., 41.,  0.,  3.,  0.,  1.,  2.,  0.,  0.,  0.],\n",
      "        [46., 39.,  0.,  3.,  0.,  1.,  1.,  0.,  0.,  0.],\n",
      "        [46., 46.,  0.,  3.,  1.,  1.,  3.,  0.,  0.,  0.],\n",
      "        [46., 42.,  0.,  3.,  0.,  1.,  2.,  0.,  0.,  0.],\n",
      "        [46., 41.,  0.,  3.,  2.,  1.,  3.,  0.,  0.,  0.],\n",
      "        [46., 41.,  0.,  3.,  0.,  1.,  3.,  0.,  0.,  0.],\n",
      "        [29., 43.,  0.,  1.,  0.,  1.,  0.,  0.,  0.,  0.],\n",
      "        [46., 53.,  0.,  3.,  1.,  1.,  4.,  0.,  0.,  0.],\n",
      "        [46., 42.,  0.,  3.,  0.,  1.,  4.,  0.,  0.,  0.],\n",
      "        [29., 41.,  0.,  1.,  0.,  1.,  0.,  0.,  0.,  0.],\n",
      "        [46., 47.,  0.,  3.,  1.,  1.,  3.,  0.,  0.,  0.],\n",
      "        [46., 46.,  0.,  3.,  1.,  1.,  4.,  0.,  0.,  0.],\n",
      "        [46., 51.,  0.,  3.,  2.,  1.,  2.,  0.,  0.,  0.],\n",
      "        [46., 35.,  0.,  3.,  0.,  1.,  2.,  0.,  0.,  0.],\n",
      "        [46., 40.,  0.,  3.,  0.,  1.,  4.,  0.,  0.,  0.],\n",
      "        [46., 49.,  0.,  3.,  1.,  1.,  4.,  0.,  0.,  0.],\n",
      "        [46., 37.,  0.,  3.,  0.,  1.,  2.,  0.,  0.,  0.]])\n",
      "tensor([[ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0],\n",
      "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18,\n",
      "         19, 20]])\n",
      "tensor(1)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch_geometric.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from torch_scatter import scatter_max\n",
    "from torch_geometric.nn import GCNConv, global_max_pool\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "\n",
    "# Hàm extract_features và extract_hyperlinks đã được định nghĩa trước đó\n",
    "def global_max_pool(x, batch):\n",
    "    # Tính max pooling trên các nút trong từng batch\n",
    "    return scatter_max(x, batch, dim=0)[0]\n",
    "\n",
    "# Hàm tạo đồ thị từ URL\n",
    "def url_to_graph_data(url, label):\n",
    "    \n",
    "    print(url)\n",
    "    try:\n",
    "        # Biểu diễn URL thành đồ thị\n",
    "        graph_data = url_to_graph(url)\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "        # Tạo dữ liệu PyTorch Geometric từ đồ thị và nhãn\n",
    "        data = Data(x=graph_data.x, edge_index=graph_data.edge_index, y=torch.tensor(label, dtype=torch.long))\n",
    "\n",
    "        \n",
    "        return data\n",
    "    except:\n",
    "        print(\"Lỗi khi url to graph\")\n",
    "\n",
    "test_url=\"https://www.ci.boerne.tx.us\"\n",
    "graph_data=url_to_graph_data(test_url,1)\n",
    "print(graph_data.x)\n",
    "print(graph_data.edge_index)\n",
    "print(graph_data.y)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset từ file hoặc database\n",
    "# Assume dataset là một danh sách các tuples (url, label)\n",
    "df = pd.read_csv('/Users/rollie/Documents/URL_Phishing_Detection/notebooks/100gnn.csv')\n",
    "newdf = list(zip(df['URL'], df['label']))\n",
    "\n",
    "\n",
    "# Chia dataset thành tập huấn luyện và tập kiểm tra\n",
    "train_data, test_data = train_test_split(newdf, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Biểu diễn dữ liệu cho tập HL\")\n",
    "# Biểu diễn mỗi URL trong tập huấn luyện thành đồ thị và tạo DataLoader cho tập huấn luyện\n",
    "#train_graph_data = [url_to_graph_data(URL, label) for URL, label in train_data]\n",
    "train_graph_data = []\n",
    "for URL, label in train_data:\n",
    "    try:\n",
    "        graph_data = url_to_graph_data(URL, label)\n",
    "        train_graph_data.append(graph_data)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing URL: {URL}. Error: {e}\")\n",
    "\n",
    "train_loader = DataLoader(train_graph_data, batch_size=8, shuffle=True)\n",
    "\n",
    "print(\"Biểu diễn dữ liệu cho tập kiểm tra\")\n",
    "# Biểu diễn mỗi URL trong tập kiểm tra thành đồ thị và tạo DataLoader cho tập kiểm tra\n",
    "test_graph_data = []\n",
    "for URL, label in test_data:\n",
    "    try:\n",
    "        graph_data = url_to_graph_data(URL, label)\n",
    "        test_graph_data.append(graph_data)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing URL: {URL}. Error: {e}\")\n",
    "test_loader = DataLoader(test_graph_data, batch_size=2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "print(len(train_graph_data))\n",
    "print(len(test_graph_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Biểu diễn dữ liệu cho tập HL\n",
      "https://www.coppercanyontrails.org\n",
      "torch.Size([21, 10])\n",
      "torch.Size([2, 20])\n",
      "https://www.stayarlington.com\n",
      "torch.Size([21, 10])\n",
      "torch.Size([2, 20])\n",
      "https://www.ssmt-reviews.com\n",
      "torch.Size([21, 10])\n",
      "torch.Size([2, 20])\n",
      "https://www.manilalivewire.com\n",
      "torch.Size([21, 10])\n",
      "torch.Size([2, 20])\n",
      "https://www.questpaymentsystems.com\n",
      "torch.Size([21, 10])\n",
      "torch.Size([2, 20])\n",
      "https://www.goriverwalk.com\n",
      "torch.Size([21, 10])\n",
      "torch.Size([2, 20])\n",
      "http://www.expoglobalservice.com\n",
      "torch.Size([21, 10])\n",
      "https://www.ridiculousupside.com\n",
      "torch.Size([21, 10])\n",
      "torch.Size([2, 20])\n",
      "https://www.allnews.ch\n",
      "torch.Size([21, 10])\n",
      "torch.Size([2, 20])\n",
      "https://www.hajker.hu\n",
      "torch.Size([21, 10])\n",
      "torch.Size([2, 20])\n",
      "https://www.bwpinebluffar.com\n",
      "torch.Size([21, 10])\n",
      "torch.Size([2, 20])\n",
      "https://www.taptapkaboom.com\n",
      "torch.Size([21, 10])\n",
      "torch.Size([2, 20])\n",
      "https://www.rowmaninternational.com\n",
      "torch.Size([21, 10])\n",
      "torch.Size([2, 20])\n",
      "https://www.yumingschool.org\n",
      "torch.Size([21, 10])\n",
      "torch.Size([2, 20])\n",
      "https://www.rawstory.com\n",
      "torch.Size([21, 10])\n",
      "torch.Size([2, 20])\n",
      "https://www.eurochicago.com\n",
      "torch.Size([21, 10])\n",
      "torch.Size([2, 20])\n",
      "https://www.stevenroyce.com\n",
      "torch.Size([21, 10])\n",
      "torch.Size([2, 20])\n",
      "https://www.ci.boerne.tx.us\n",
      "torch.Size([21, 10])\n",
      "torch.Size([2, 20])\n",
      "https://www.avanluce.com\n",
      "torch.Size([21, 10])\n",
      "torch.Size([2, 20])\n",
      "https://wild-morning-5807.wasteroadmored.workers.dev/\n",
      "torch.Size([21, 10])\n",
      "torch.Size([2, 20])\n",
      "https://www.jpharmtechnol.com\n",
      "torch.Size([21, 10])\n",
      "torch.Size([2, 20])\n",
      "https://www.put.ac.ir\n",
      "torch.Size([21, 10])\n",
      "torch.Size([2, 20])\n",
      "https://www.serverlesschats.com\n",
      "torch.Size([21, 10])\n",
      "torch.Size([2, 20])\n",
      "https://www.givot.co.il\n",
      "torch.Size([21, 10])\n",
      "torch.Size([2, 20])\n",
      "https://www.police1.com\n",
      "torch.Size([21, 10])\n",
      "torch.Size([2, 20])\n",
      "https://www.wellfitandfed.com\n",
      "torch.Size([21, 10])\n",
      "torch.Size([2, 20])\n",
      "https://bafybeiay6xqd5gfmoxtxwkstivxnghldkvqyrdup5d3sl67wep5qprfxgy.ipfs.cf-ipfs.com/qeny.html#a@b.com\n",
      "torch.Size([21, 10])\n",
      "torch.Size([2, 20])\n",
      "https://www.foodloversrecipes.com\n",
      "torch.Size([21, 10])\n",
      "torch.Size([2, 20])\n",
      "https://www.fotawildlife.ie\n",
      "torch.Size([21, 10])\n",
      "torch.Size([2, 20])\n",
      "https://www.sunshinevillaorlando.com\n",
      "torch.Size([21, 10])\n",
      "torch.Size([2, 20])\n",
      "https://www.bubwith.net\n",
      "torch.Size([21, 10])\n",
      "torch.Size([2, 20])\n",
      "https://www.elizabethnj.org\n",
      "torch.Size([21, 10])\n",
      "torch.Size([2, 20])\n",
      "Biểu diễn dữ liệu cho tập kiểm tra\n",
      "https://www.susannahweiland.co.uk\n",
      "torch.Size([21, 10])\n",
      "torch.Size([2, 20])\n",
      "https://www.me-tis.net\n",
      "torch.Size([21, 10])\n",
      "torch.Size([2, 20])\n",
      "https://www.leroyseafood.com\n",
      "torch.Size([21, 10])\n",
      "torch.Size([2, 20])\n",
      "https://www.rasmussenreports.com\n",
      "torch.Size([21, 10])\n",
      "torch.Size([2, 20])\n",
      "https://www.samyeling.org\n",
      "torch.Size([21, 10])\n",
      "torch.Size([2, 20])\n",
      "https://www.derewonko.com\n",
      "torch.Size([21, 10])\n",
      "https://www.twardoch.com\n",
      "torch.Size([21, 10])\n",
      "torch.Size([2, 20])\n",
      "https://www.ordredemaltefrance.org\n",
      "torch.Size([21, 10])\n",
      "torch.Size([2, 20])\n",
      "25\n",
      "...\n",
      "7\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "'GCNConv' received a tuple of node features as input while this layer does not support bipartite message passing. Please try other layers such as 'SAGEConv' or 'GraphConv' instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/rollie/Documents/URL_Phishing_Detection/notebooks/GNNs.ipynb Cell 11\u001b[0m line \u001b[0;36m9\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rollie/Documents/URL_Phishing_Detection/notebooks/GNNs.ipynb#X22sZmlsZQ%3D%3D?line=96'>97</a>\u001b[0m \u001b[39mfor\u001b[39;00m batch \u001b[39min\u001b[39;00m train_loader:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rollie/Documents/URL_Phishing_Detection/notebooks/GNNs.ipynb#X22sZmlsZQ%3D%3D?line=97'>98</a>\u001b[0m     optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/rollie/Documents/URL_Phishing_Detection/notebooks/GNNs.ipynb#X22sZmlsZQ%3D%3D?line=98'>99</a>\u001b[0m     output \u001b[39m=\u001b[39m model(batch)\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/rollie/Documents/URL_Phishing_Detection/notebooks/GNNs.ipynb#X22sZmlsZQ%3D%3D?line=99'>100</a>\u001b[0m     loss \u001b[39m=\u001b[39m criterion(output, batch\u001b[39m.\u001b[39my)\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/rollie/Documents/URL_Phishing_Detection/notebooks/GNNs.ipynb#X22sZmlsZQ%3D%3D?line=100'>101</a>\u001b[0m     loss\u001b[39m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/anaconda3/envs/myenv/lib/python3.8/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/myenv/lib/python3.8/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[1;32m/Users/rollie/Documents/URL_Phishing_Detection/notebooks/GNNs.ipynb Cell 11\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rollie/Documents/URL_Phishing_Detection/notebooks/GNNs.ipynb#X22sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, data):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rollie/Documents/URL_Phishing_Detection/notebooks/GNNs.ipynb#X22sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m     x, edge_index \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mx, data\u001b[39m.\u001b[39medge_index\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/rollie/Documents/URL_Phishing_Detection/notebooks/GNNs.ipynb#X22sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv1(x, edge_index)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rollie/Documents/URL_Phishing_Detection/notebooks/GNNs.ipynb#X22sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv2(x, edge_index)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rollie/Documents/URL_Phishing_Detection/notebooks/GNNs.ipynb#X22sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m     x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mrelu(x)\n",
      "File \u001b[0;32m~/anaconda3/envs/myenv/lib/python3.8/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/myenv/lib/python3.8/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/myenv/lib/python3.8/site-packages/torch_geometric/nn/conv/gcn_conv.py:231\u001b[0m, in \u001b[0;36mGCNConv.forward\u001b[0;34m(self, x, edge_index, edge_weight)\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x: Tensor, edge_index: Adj,\n\u001b[1;32m    228\u001b[0m             edge_weight: OptTensor \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m    230\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(x, (\u001b[39mtuple\u001b[39m, \u001b[39mlist\u001b[39m)):\n\u001b[0;32m--> 231\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m received a tuple \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    232\u001b[0m                          \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mof node features as input while this layer \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    233\u001b[0m                          \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mdoes not support bipartite message passing. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    234\u001b[0m                          \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mPlease try other layers such as \u001b[39m\u001b[39m'\u001b[39m\u001b[39mSAGEConv\u001b[39m\u001b[39m'\u001b[39m\u001b[39m or \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    235\u001b[0m                          \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39mGraphConv\u001b[39m\u001b[39m'\u001b[39m\u001b[39m instead\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    237\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnormalize:\n\u001b[1;32m    238\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(edge_index, Tensor):\n",
      "\u001b[0;31mValueError\u001b[0m: 'GCNConv' received a tuple of node features as input while this layer does not support bipartite message passing. Please try other layers such as 'SAGEConv' or 'GraphConv' instead"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "# Load dataset từ file hoặc database\n",
    "# Assume dataset là một danh sách các tuples (url, label)\n",
    "df = pd.read_csv('/Users/rollie/Documents/URL_Phishing_Detection/notebooks/gnn-file-cut.csv')\n",
    "newdf = list(zip(df['URL'], df['label']))\n",
    "\n",
    "\n",
    "# Chia dataset thành tập huấn luyện và tập kiểm tra\n",
    "train_data, test_data = train_test_split(newdf, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Biểu diễn dữ liệu cho tập HL\")\n",
    "# Biểu diễn mỗi URL trong tập huấn luyện thành đồ thị và tạo DataLoader cho tập huấn luyện\n",
    "#train_graph_data = [url_to_graph_data(URL, label) for URL, label in train_data]\n",
    "train_graph_data = []\n",
    "for URL, label in train_data:\n",
    "    try:\n",
    "        graph_data = url_to_graph_data(URL, label)\n",
    "        train_graph_data.append(graph_data)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing URL: {URL}. Error: {e}\")\n",
    "\n",
    "train_loader = DataLoader(train_graph_data, batch_size=2, shuffle=True)\n",
    "\n",
    "print(\"Biểu diễn dữ liệu cho tập kiểm tra\")\n",
    "# Biểu diễn mỗi URL trong tập kiểm tra thành đồ thị và tạo DataLoader cho tập kiểm tra\n",
    "test_graph_data = []\n",
    "for URL, label in test_data:\n",
    "    try:\n",
    "        graph_data = url_to_graph_data(URL, label)\n",
    "        test_graph_data.append(graph_data)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing URL: {URL}. Error: {e}\")\n",
    "test_loader = DataLoader(test_graph_data, batch_size=2, shuffle=False)\n",
    "# Định nghĩa mô hình GNN\n",
    "class GNNModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(GNNModel, self).__init__()\n",
    "        self.conv1 = GCNConv(input_dim, hidden_dim)\n",
    "        self.conv2 = GCNConv(hidden_dim, hidden_dim)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = torch.relu(x)\n",
    "        x = global_max_pool(x, data.batch)  # Global max pooling\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "# Khởi tạo mô hình\n",
    "model = GNNModel(input_dim=10, hidden_dim=10, output_dim=2)\n",
    "\n",
    "# Định nghĩa hàm loss và optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Chia dữ liệu thành 5 fold\n",
    "kf = KFold(n_splits=5)\n",
    "# Đánh giá trên từng fold\n",
    "fold_accuracies = []\n",
    "for train_index, test_index in kf.split(train_graph_data):  # dataset là tập dữ liệu đầy đủ\n",
    "    train_data = [train_graph_data[i] for i in train_index]\n",
    "    print(len(train_data))\n",
    "    print(\"...\")\n",
    "    \n",
    "    test_data = [train_graph_data[i] for i in test_index]\n",
    "    print(len(test_data))\n",
    "    from torch_geometric.data import Data\n",
    "\n",
    "\n",
    "\n",
    "# Tạo DataLoader với custom collate function\n",
    "    #train_loader = DataLoader(train_data, batch_size=8, shuffle=True, collate_fn=custom_collate)\n",
    "    #test_loader = DataLoader(test_data, batch_size=2, shuffle=False, collate_fn=custom_collate)\n",
    "\n",
    "    train_loader = DataLoader(train_data, batch_size= 8, shuffle=True)\n",
    "    test_loader = DataLoader(test_data, batch_size=2, shuffle=False)\n",
    "\n",
    "\n",
    " # Huấn luyện mô hình\n",
    "    for epoch in range(10):  # Ví dụ cho 10 epochs\n",
    "        model.train()\n",
    "        for batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            output = model(batch)\n",
    "            loss = criterion(output, batch.y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    # Đánh giá mô hình trên tập kiểm tra\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for batch in test_loader:\n",
    "            output = model(batch)\n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "            total += batch.y.size(0)\n",
    "            correct += (predicted == batch.y).sum().item()\n",
    "\n",
    "        fold_accuracy = correct / total\n",
    "        fold_accuracies.append(fold_accuracy)\n",
    "\n",
    "# Tính trung bình độ chính xác trên các fold\n",
    "mean_accuracy = sum(fold_accuracies) / len(fold_accuracies)\n",
    "print('Mean accuracy across 5 folds:', mean_accuracy)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
