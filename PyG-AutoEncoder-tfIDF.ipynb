{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db6ea671-60fe-4cfe-ae8f-d7c37cbdebf0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from utils import run_ML\n",
    "from sklearn.metrics import f1_score\n",
    "from itertools import groupby\n",
    "import pickle\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9132d59-ef74-44d2-91aa-e89d9b5fc54d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51996577-859a-466e-a40f-b60f6a51a8d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5ac7c73-a600-48e9-8931-3afa1679e506",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install tldextract\n",
    "# !pip install torch_geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4b90b7a-8d1a-4472-889c-bc87ef4a9706",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# data_dir = \"data/URLdatasetX2_1.csv\"\n",
    "# df = pd.read_csv(data_dir,index_col=0)\n",
    "# n_subsample = 3000 # all\n",
    "# smalldata = df.sample(n = n_subsample, random_state=1) #PC\n",
    "# smalldata = df\n",
    "# # get labels of urls\n",
    "# labels = smalldata.iloc[:,-1].values\n",
    "# from sklearn.preprocessing import LabelEncoder\n",
    "# label_encoder = LabelEncoder()\n",
    "# labels = label_encoder.fit_transform(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5aca4692-f14f-4210-88cb-68aa5654bbc7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# data_dir = \"data/LegitPhish_50_50.csv\"\n",
    "# data_dir = \"data/LegitPhish_80_20.csv\"\n",
    "data_dir = \"data/LegitPhish_90_10.csv\"\n",
    "df = pd.read_csv(data_dir,index_col=0)\n",
    "n_subsample = 3000 # all\n",
    "smalldata = df.sample(n = n_subsample, random_state=1) #PC\n",
    "# smalldata = df\n",
    "# get labels of urls\n",
    "labels = smalldata.iloc[:,-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fcd08658-b0b2-44af-8058-95c255eed904",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1: 1997, 0: 1003})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import collections\n",
    "counter = collections.Counter(labels)\n",
    "counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa0a837d-63e3-40cf-afc9-9593072d34e4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Conventional Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3cd8d0e0-af10-42b5-9bd9-bced95415a22",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils import extract_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "155e525e-f2fc-49d2-8be2-3b64ea9b67b4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'domain': 'www.example.com', 'num_subdomains': 2, 'contains_ip': 0, 'path_length': 20, 'num_path_segments': 3, 'uses_https': 0, 'file_extension': 'html', 'count_special_characters': 11, 'count_non_alphanumeric_characters': 11, 'TLD': 'com', 'count_obfuscated_characters': 0, 'letter_ratio_in_url': 0.7380952380952381, 'digit_ratio_in_url': 0.0, 'count_equals_in_url': 2, 'NoOfAmpersandInURL': 0, 'CharContinuationRate': 0.11904761904761904, 'ratio_obfuscated_characters': 0.0, 'NoOfQMarkInURL': 0}\n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "url = \"http://www.example.com/path/to/==file.html\"\n",
    "url_features = extract_features(url)\n",
    "print(url_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2377259d-5b19-4f0f-8758-96b1b330d117",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print(url_features.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "66cae4c3-a178-435c-9830-a4f5fd8fdc06",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get numerical and catergorical features\n",
    "phish_url = []\n",
    "for link in list(smalldata.iloc[:,0]):\n",
    "    url_features = extract_features(link)\n",
    "    phish_url.append(list(url_features.values())[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "664a11ec-0a42-4a01-91f2-208aa5796b64",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "phish_url_df = pd.DataFrame(phish_url, columns = list(url_features.keys())[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "383162e7-d058-471e-b921-d2e983efe066",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# phish_url_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aabba33a-d06a-4a3f-b021-ff8cbde0088c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "phish_url_df.iloc[:,5] = pd.Categorical(phish_url_df.iloc[:,5]).codes\n",
    "phish_url_df.iloc[:,8] = pd.Categorical(phish_url_df.iloc[:,8]).codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1cc59152-00c2-41ec-acf5-afeae474f39e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_subdomains</th>\n",
       "      <th>contains_ip</th>\n",
       "      <th>path_length</th>\n",
       "      <th>num_path_segments</th>\n",
       "      <th>uses_https</th>\n",
       "      <th>file_extension</th>\n",
       "      <th>count_special_characters</th>\n",
       "      <th>count_non_alphanumeric_characters</th>\n",
       "      <th>TLD</th>\n",
       "      <th>count_obfuscated_characters</th>\n",
       "      <th>letter_ratio_in_url</th>\n",
       "      <th>digit_ratio_in_url</th>\n",
       "      <th>count_equals_in_url</th>\n",
       "      <th>NoOfAmpersandInURL</th>\n",
       "      <th>CharContinuationRate</th>\n",
       "      <th>ratio_obfuscated_characters</th>\n",
       "      <th>NoOfQMarkInURL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>80</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>0.864407</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.050847</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   num_subdomains  contains_ip  path_length  num_path_segments  uses_https  \\\n",
       "0               2            0            1                  1           0   \n",
       "1               3            0           80                  7           0   \n",
       "\n",
       "  file_extension  count_special_characters  count_non_alphanumeric_characters  \\\n",
       "0              0                         6                                  6   \n",
       "1              0                        16                                 16   \n",
       "\n",
       "  TLD  count_obfuscated_characters  letter_ratio_in_url  digit_ratio_in_url  \\\n",
       "0  35                            0             0.823529                 0.0   \n",
       "1  35                            0             0.864407                 0.0   \n",
       "\n",
       "   count_equals_in_url  NoOfAmpersandInURL  CharContinuationRate  \\\n",
       "0                    0                   0              0.058824   \n",
       "1                    0                   0              0.050847   \n",
       "\n",
       "   ratio_obfuscated_characters  NoOfQMarkInURL  \n",
       "0                          0.0               0  \n",
       "1                          0.0               0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phish_url_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "503ed86a-9489-487f-8054-8c0d4653da36",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run:  0 , fold:  0\n",
      "Train freq:  [797, 1603]\n",
      "kNN, LightGBM, Run:  0 , fold:  1\n",
      "Train freq:  [796, 1604]\n",
      "kNN, LightGBM, Run:  0 , fold:  2\n",
      "Train freq:  [806, 1594]\n",
      "kNN, LightGBM, Run:  0 , fold:  3\n",
      "Train freq:  [807, 1593]\n",
      "kNN, LightGBM, Run:  0 , fold:  4\n",
      "Train freq:  [806, 1594]\n",
      "kNN, LightGBM, ['kNN', 'LightGBM']\n",
      "[0.75 0.85]\n"
     ]
    }
   ],
   "source": [
    "# test on URLs features\n",
    "run_ML(phish_url_df, labels, \"URLdatasetX2\", \"manual\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c999c69c-2338-4ea3-a5df-2bbd10c0dd49",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run:  0 , fold:  0\n",
      "Train freq:  [797, 1603]\n",
      "kNN, LightGBM, Run:  0 , fold:  1\n",
      "Train freq:  [796, 1604]\n",
      "kNN, LightGBM, Run:  0 , fold:  2\n",
      "Train freq:  [806, 1594]\n",
      "kNN, LightGBM, Run:  0 , fold:  3\n",
      "Train freq:  [807, 1593]\n",
      "kNN, LightGBM, Run:  0 , fold:  4\n",
      "Train freq:  [806, 1594]\n",
      "kNN, LightGBM, ['kNN', 'LightGBM']\n",
      "[0.73 0.81]\n"
     ]
    }
   ],
   "source": [
    "## test on numerical URLs features\n",
    "from utils import extract_numerical_features\n",
    "phish_url = []\n",
    "for link in list(smalldata.iloc[:,0]):\n",
    "    url_features = extract_numerical_features(link)\n",
    "    phish_url.append(list(url_features.values()))\n",
    "run_ML(np.array(phish_url), labels, \"URLdatasetX2\", \"manual_numerical\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2f45c022-60fb-4a87-9b53-10f2a093f7fc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7936507936507937\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "n_samples = len(smalldata.index)\n",
    "train_idx = list(np.random.choice(list(range(n_samples)), int(0.8*n_samples), replace=False))\n",
    "test_idx = list(set(list(range(n_samples))).difference(set(train_idx)))\n",
    "data_df = np.array(phish_url)\n",
    "import lightgbm as lgb\n",
    "model = lgb.LGBMClassifier(verbose=-1)\n",
    "model.fit(data_df[train_idx], labels[train_idx])\n",
    "y_predict=model.predict(data_df[test_idx]) \n",
    "print(f1_score(y_predict, labels[test_idx], average='macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "695c2e9e-0c05-4e9d-8abe-d89cf1519c87",
   "metadata": {
    "tags": []
   },
   "source": [
    "# PyG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef79b7fe-f017-4894-a558-ecf95e00c992",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Extract graph features from URLs for PyG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2be46503-1dab-4c89-9a14-2859346a62ac",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8831216426361683\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>CountVectorizer(analyzer=&#x27;char&#x27;, ngram_range=(1, 4))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;CountVectorizer<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\">?<span>Documentation for CountVectorizer</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>CountVectorizer(analyzer=&#x27;char&#x27;, ngram_range=(1, 4))</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "CountVectorizer(analyzer='char', ngram_range=(1, 4))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer\n",
    "# List of URLs\n",
    "urls = list(smalldata['url'])\n",
    "# Tokenization and N-grams Generation\n",
    "# You can adjust ngram_range to extract different n-grams (e.g., (1, 1) for unigrams, (2, 2) for bigrams, etc.)\n",
    "vectorizer = CountVectorizer(analyzer='char', ngram_range=(1, 4)) #5\n",
    "X_counts = vectorizer.fit_transform(urls)\n",
    "# TF-IDF Transformation\n",
    "transformer = TfidfTransformer()\n",
    "X_tfidf = transformer.fit_transform(X_counts)\n",
    "# Extracted Features\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "X_counts_data = X_counts.toarray() # not necessary\n",
    "# Train lgb\n",
    "model_lgb = lgb.LGBMClassifier(verbose=-1)\n",
    "model_lgb.fit(X_counts_data[train_idx], labels[train_idx])\n",
    "y_predict=model_lgb.predict(X_counts_data[test_idx]) \n",
    "print(f1_score(y_predict, labels[test_idx], average='macro'))\n",
    "feature_imp_gain = pd.DataFrame(sorted(zip(model_lgb.booster_.feature_importance(importance_type='gain'),\n",
    "                                           feature_names), reverse=True), columns=['Value', 'Feature'])\n",
    "feature_imp_split = pd.DataFrame(sorted(zip(model_lgb.booster_.feature_importance(importance_type='split'),\n",
    "                                            feature_names), reverse=True), columns=['Value', 'Feature'])\n",
    "top_ngrams_features = list(set(list(feature_imp_gain.iloc[:200,1]) + list(feature_imp_split.iloc[:200,1])))\n",
    "cv = CountVectorizer(analyzer='char', ngram_range=(1, 4))\n",
    "cv.fit(top_ngrams_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8ec2dd2e-e01b-4b9d-bb3e-f8a36ec4e787",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_feature_CountVectorizer(model, url):\n",
    "    return model.transform([url]).toarray().flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f60ec269-beed-4faf-8010-9465bafd2fc1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# extract_feature_CountVectorizer(cv, urls[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2676fb9b-966b-4acf-a071-89bea32f7bb1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from requests.exceptions import ConnectionError\n",
    "import traceback\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "406988f9-e960-4a0d-87da-64ae205ff5b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# return root and hyperlinks features\n",
    "def get_graph_features_CountVectorizer(idx):\n",
    "    url = smalldata.iloc[idx,0]\n",
    "    root_feature = extract_feature_CountVectorizer(cv, url) # dict\n",
    "    hyperlink_data = [list(root_feature)]\n",
    "    try:    \n",
    "        # find all hyperlinks\n",
    "        reqs = requests.get(url, allow_redirects=False)\n",
    "        soup = BeautifulSoup(reqs.text, 'html.parser')\n",
    "        urls = []\n",
    "        count = 0;\n",
    "        for link in soup.find_all('a'):\n",
    "            # print(link.get('href'))\n",
    "            weblink = link.get('href')\n",
    "            if (weblink is not None) and ('http' in weblink):\n",
    "                urls.append(weblink)\n",
    "            count += 1\n",
    "            if count > 50:\n",
    "                break\n",
    "        # extract numerical features in from hyperlinks\n",
    "        if len(urls) > 0:\n",
    "            for link in urls:\n",
    "                try:\n",
    "                    url_features = extract_feature_CountVectorizer(cv, link)\n",
    "                    datalinkssss = list(url_features)\n",
    "                    hyperlink_data.append(datalinkssss)\n",
    "                except ValueError as ve:\n",
    "                    # datalinkssss = list(np.zeros(15))#raw_graph_features\n",
    "                    error_here = 1;\n",
    "                # hyperlink_data.append(datalinkssss)\n",
    "        else:\n",
    "            # hyperlink_data.append(list(np.zeros(15)))#raw_graph_features\n",
    "            error_here = 1;\n",
    "    \n",
    "    # except ConnectionError as e:\n",
    "    #     # print(\"No rep\", end = ',')\n",
    "    #     # hyperlink_data.append(list(np.zeros(15))) #raw_graph_features\n",
    "    #     error_here = 1; #v2\n",
    "    except Exception as e:\n",
    "        #logging.error(traceback.format_exc())\n",
    "        error_here = 1\n",
    "    \n",
    "    return (idx,  hyperlink_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d758fb40-1b9a-415b-9072-b4d3b15c3b9e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# results = [get_graph_features_CountVectorizer(i) for i in range(n_test_samples)]\n",
    "# results = []\n",
    "# for i in range(213, n_test_samples):\n",
    "#     print(i, end =',')\n",
    "#     results.append(get_graph_features_CountVectorizer(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5e3459ba-c3fe-4178-8115-3984b611e23e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import multiprocessing\n",
    "\n",
    "multiprocessing.cpu_count()\n",
    "n_cores = min(30, int(multiprocessing.cpu_count()-2))\n",
    "n_cores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8b8652ab-ab89-4a6d-bfcb-3c0c548db9bf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LegitPhish_90_10'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_name_0123 = data_dir.split('/')[-1][:-4]\n",
    "data_name_0123"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "766cd5a5-dcb4-4f03-a0ed-ee9d3ba25d9e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File does not exist! Process the data\n"
     ]
    }
   ],
   "source": [
    "data_name_0123 = data_dir.split('/')[-1][:-4]\n",
    "# data_file = \"data/raw_graph_features_v2.pickle\" # first version \n",
    "data_file = \"data/\"+data_name_0123+str(n_subsample)+\"_raw_graph_features_CountVectorizer.pickle\" # first version \n",
    "my_file = Path(data_file)\n",
    "if my_file.is_file():\n",
    "    print(\"File exist! Load the data\")\n",
    "    with open(data_file, \"rb\") as fp:   # Unpickling\n",
    "        results = pickle.load(fp)\n",
    "else:\n",
    "    print(\"File does not exist! Process the data\")\n",
    "    n_test_samples = int(smalldata.shape[0]) # how many link we want to test\n",
    "    from joblib import Parallel, delayed\n",
    "    results = Parallel(n_jobs=n_cores)(delayed(get_graph_features_CountVectorizer)(i) for i in range(n_test_samples)) # test on 100 links\n",
    "    with open(data_file, \"wb\") as fp:   #Pickling\n",
    "        pickle.dump(results, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bee1e3a-efd0-41a0-8c14-ed23c50940a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71158727-28ae-4c6d-aa68-f8430da884a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9aaf9a-c170-49a2-99af-bcc50ee7d6cc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Graph data class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836dd0a7-8ac7-487f-a204-7de4c6c60c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Transfer data object to GPU.\n",
    "# device = torch.device('cuda')\n",
    "# data = data.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05cfcd5d-7cfb-4489-8df7-c845a56503c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data, Dataset\n",
    "\n",
    "class GraphClassificationDataset(Dataset):\n",
    "    def __init__(self, graphs):\n",
    "        self.graphs = graphs\n",
    "        # self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.graphs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        graph = self.graphs[idx]\n",
    "        # label = self.labels[idx]\n",
    "        return graph\n",
    "    \n",
    "    def get(): pass\n",
    "\n",
    "    def len(): pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53be4688-e4d2-4401-917c-31bf7ce340b5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Create dataset class for PyG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8bd6a84-04a7-4f20-b6be-04f31d2a1916",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume you have a list of graphs represented as Data objects and a corresponding list of labels\n",
    "# Only take the url with more than 4 hyperlinks\n",
    "graphs = []\n",
    "labels_list = []\n",
    "for i in range(len(results)):\n",
    "    idx, graph_feature = results[i]\n",
    "    n_hyperlinks = len(graph_feature)-1\n",
    "    child_id = [i+1 for i in range(n_hyperlinks)]\n",
    "    source_id = list(np.zeros(n_hyperlinks).astype(int))\n",
    "    # edge_index = torch.tensor([source_id + child_id,\n",
    "    #                            child_id + source_id], dtype=torch.long)\n",
    "    edge_index = torch.tensor([source_id,\n",
    "                               child_id], dtype=torch.long)\n",
    "    x = torch.tensor(graph_feature, dtype=torch.float)\n",
    "    y = torch.tensor([labels[idx]], dtype=torch.int64)\n",
    "    data = Data(x=x, edge_index=edge_index, y = y)\n",
    "    if n_hyperlinks > -1:\n",
    "        graphs.append(data)\n",
    "        labels_list.append(labels[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "795e7cc1-6f35-4ed2-863a-34cece9a52da",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train freq: \", [len(list(group)) for key, group in groupby(sorted(labels_list))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a3a5ee-7d6e-412c-8ec3-7a653bbbb72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = GraphClassificationDataset(graphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc5a361-8c19-48a4-a651-f46ca40ffdbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print()\n",
    "print(f'Dataset: {dataset}:')\n",
    "print('====================')\n",
    "print(f'Number of graphs: {len(dataset)}')\n",
    "print(f'Number of features: {dataset.num_features}')\n",
    "print(f'Number of classes: {dataset.num_classes}')\n",
    "\n",
    "data = dataset[0]  # Get the first graph object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e69f8dd0-7d89-4d23-9051-1e86c544d508",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = dataset.shuffle()\n",
    "n_samples = len(dataset)\n",
    "np.random.seed(0) \n",
    "train_idx = list(np.random.choice(list(range(n_samples)), int(0.8*n_samples), replace=False))\n",
    "test_idx = list(set(list(range(n_samples))).difference(set(train_idx)))\n",
    "train_idx[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def48b62-971c-4e4f-ac9c-126a06f2739d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataset = dataset[:int(0.8*n_samples)]\n",
    "# test_dataset = dataset[int(0.8*n_samples):]\n",
    "train_dataset = [dataset[idx] for idx in train_idx]\n",
    "test_dataset = [dataset[idx] for idx in test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b8c74ac-9ca9-498f-b5dc-ee77ab28f254",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_dataset), len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f115489a-ccce-4f40-9355-452d4cc6b307",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65bc21d4-1976-46ce-8640-d6994adafd0c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Build and train PyG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f975f01-7eb2-4b3e-9bd7-b8c897785e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Linear\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.nn import global_mean_pool, global_max_pool\n",
    "\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super(GCN, self).__init__()\n",
    "        torch.manual_seed(12345)\n",
    "        self.conv1 = GCNConv(dataset.num_node_features, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.conv3 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.lin = Linear(hidden_channels, dataset.num_classes)\n",
    "        self.linconcat = Linear(2*hidden_channels, dataset.num_classes)\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        # 1. Obtain node embeddings \n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = self.conv3(x, edge_index)\n",
    "\n",
    "        # 2. Readout layer\n",
    "        x = global_mean_pool(x, batch)  # [batch_size, hidden_channels]\n",
    "\n",
    "        # 3. Apply a final classifier\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.lin(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd41cc6b-7c71-4d42-9b24-5419f05f98c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GCN(hidden_channels=64)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "\n",
    "    for data in train_loader:  # Iterate in batches over the training dataset.\n",
    "        # print(data.x.shape)\n",
    "        out = model(data.x, data.edge_index, data.batch)  # Perform a single forward pass.\n",
    "        loss = criterion(out, data.y)  # Compute the loss.\n",
    "        loss.backward()  # Derive gradients.\n",
    "        optimizer.step()  # Update parameters based on gradients.\n",
    "        optimizer.zero_grad()  # Clear gradients.\n",
    "\n",
    "def test(loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    # for data in loader:  # Iterate in batches over the training/test dataset.\n",
    "    #     out = model(data.x, data.edge_index, data.batch)  \n",
    "    #     pred = out.argmax(dim=1)  # Use the class with highest probability.\n",
    "    #     correct += int((pred == data.y).sum())  # Check against ground-truth labels.\n",
    "    # return correct / len(loader.dataset)  # Derive ratio of correct predictions.\n",
    "    true_labels = []\n",
    "    pred_labels = []\n",
    "    for data in loader:  # Iterate in batches over the training/test dataset.\n",
    "        out = model(data.x, data.edge_index, data.batch)  \n",
    "        pred = out.argmax(dim=1)  # Use the class with highest probability.\n",
    "        correct += int((pred == data.y).sum())  # Check against ground-truth labels.\n",
    "        true_labels += data.y.tolist()\n",
    "        pred_labels += pred.tolist()\n",
    "        # print(pred_labels)\n",
    "    return f1_score(true_labels, pred_labels, average='macro')\n",
    "\n",
    "for epoch in range(0, 20):\n",
    "    train()\n",
    "    train_acc = test(train_loader)\n",
    "    test_acc = test(test_loader)\n",
    "    if epoch % 10 == 0:\n",
    "        print(f'Epoch: {epoch:03d}, Train F1: {train_acc:.4f}, Test F1: {test_acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb46af3-23a3-4c2b-a73a-496e34bdd7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ['kNN', 'LightGBM'] min, max, avg of child features [0.82 0.92]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7128b95-c87e-4614-b2b6-65b372846199",
   "metadata": {
    "tags": []
   },
   "source": [
    "### GNN for dim. reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b2d0b6c-94b6-46fe-ae04-8a22b8244a20",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Net 1: 0.87, 0.88"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e113dd-b47e-4696-854f-6cd2bf99f479",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.nn import Linear\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.nn import global_mean_pool, global_max_pool\n",
    "\n",
    "class GCNdimReduce(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super(GCNdimReduce, self).__init__()\n",
    "        torch.manual_seed(12345)\n",
    "        self.conv1 = GCNConv(dataset.num_node_features, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.conv3 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.lin1 = Linear(hidden_channels, hidden_channels)\n",
    "        self.lin2 = Linear(hidden_channels, dataset.num_classes)\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        # 1. Obtain node embeddings \n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = self.conv3(x, edge_index)\n",
    "\n",
    "        # 2. Readout layer\n",
    "        x = global_mean_pool(x, batch)  # [batch_size, hidden_channels]\n",
    "\n",
    "        # 3. Apply a final classifier\n",
    "        x = self.lin1(x)\n",
    "        x = F.dropout(x, p=0.3, training=self.training)\n",
    "        x = self.lin2(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def dimReduce(self, x, edge_index, batch):\n",
    "        # 1. Obtain node embeddings \n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = self.conv2(x, edge_index)\n",
    "        # x = x.relu()\n",
    "        # x = self.conv3(x, edge_index)\n",
    "\n",
    "        # 2. Readout layer\n",
    "        x = global_mean_pool(x, batch)  # [batch_size, hidden_channels]\n",
    "\n",
    "        # # 3. Apply a final classifier\n",
    "        x = self.lin1(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "812b201f-f9cd-4c2c-8fb2-299019c33656",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Net 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49cab21a-1649-4cfb-8b32-775372f8855e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.nn import Linear\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.nn import global_mean_pool, global_max_pool\n",
    "\n",
    "class GCNdimReduceV2(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super(GCNdimReduceV2, self).__init__()\n",
    "        torch.manual_seed(12345)\n",
    "        self.conv1 = GCNConv(dataset.num_node_features, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.conv3 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.lin1 = Linear(hidden_channels, hidden_channels)\n",
    "        self.lin2 = Linear(hidden_channels, dataset.num_classes)\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        # 1. Obtain node embeddings \n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.conv3(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.conv3(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = x.relu()\n",
    "       \n",
    "        # 2. Readout layer\n",
    "        x = global_mean_pool(x, batch)  # [batch_size, hidden_channels]\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        # 3. Apply a final classifier\n",
    "        x = self.lin1(x)\n",
    "        x = x.relu()\n",
    "        x = self.lin2(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def dimReduce(self, x, edge_index, batch):\n",
    "        # 1. Obtain node embeddings \n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.conv3(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.conv3(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = global_mean_pool(x, batch)  # [batch_size, hidden_channels]\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.lin1(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b4c5b2-1bbe-4de7-b566-e55cddcae716",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e36e2e-3075-4846-9958-66eafd46a08a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_hidden_channels = 16\n",
    "model = GCNdimReduce(hidden_channels=n_hidden_channels)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "\n",
    "    for data in train_loader:  # Iterate in batches over the training dataset.\n",
    "        # print(data.x.shape)\n",
    "        out = model(data.x, data.edge_index, data.batch)  # Perform a single forward pass.\n",
    "        loss = criterion(out, data.y)  # Compute the loss.\n",
    "        loss.backward()  # Derive gradients.\n",
    "        optimizer.step()  # Update parameters based on gradients.\n",
    "        optimizer.zero_grad()  # Clear gradients.\n",
    "\n",
    "def test(loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    true_labels = []\n",
    "    pred_labels = []\n",
    "    for data in loader:  # Iterate in batches over the training/test dataset.\n",
    "        out = model(data.x, data.edge_index, data.batch)  \n",
    "        pred = out.argmax(dim=1)  # Use the class with highest probability.\n",
    "        correct += int((pred == data.y).sum())  # Check against ground-truth labels.\n",
    "        true_labels += data.y.tolist()\n",
    "        pred_labels += pred.tolist()\n",
    "    return f1_score(true_labels, pred_labels, average='macro')\n",
    "\n",
    "for epoch in range(0, 10):\n",
    "    train()\n",
    "    train_acc = test(train_loader)\n",
    "    test_acc = test(test_loader)\n",
    "    if epoch % 1 == 0:\n",
    "        print(f'Epoch: {epoch:03d}, Train F1: {train_acc:.4f}, Test F1: {test_acc:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd05c57-15eb-4dff-8214-e14c1e64ead7",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c089665-699b-4361-abc9-90a5add2357f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "phish_url_vectorizer = []\n",
    "for link in list(smalldata.iloc[:,0]):\n",
    "    url_features = extract_feature_CountVectorizer(cv, link)\n",
    "    phish_url_vectorizer.append(list(url_features))\n",
    "# run_ML(concatGNN, labels, \"URLdatasetX2\", \"concatGNN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e0211a-4123-4693-a978-83c7e103a693",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_model(all_data_loader, train_loader, test_loader, n_hidden_channels = 16, n_epoch=1, lr=0.001):\n",
    "    # n_hidden_channels = 16\n",
    "    model = GCNdimReduce(hidden_channels=n_hidden_channels)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    def train():\n",
    "        model.train()\n",
    "\n",
    "        for data in train_loader:  # Iterate in batches over the training dataset.\n",
    "            # print(data.x.shape)\n",
    "            out = model(data.x, data.edge_index, data.batch)  # Perform a single forward pass.\n",
    "            loss = criterion(out, data.y)  # Compute the loss.\n",
    "            loss.backward()  # Derive gradients.\n",
    "            optimizer.step()  # Update parameters based on gradients.\n",
    "            optimizer.zero_grad()  # Clear gradients.\n",
    "\n",
    "    def test(loader):\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        true_labels = []\n",
    "        pred_labels = []\n",
    "        for data in loader:  # Iterate in batches over the training/test dataset.\n",
    "            out = model(data.x, data.edge_index, data.batch)  \n",
    "            pred = out.argmax(dim=1)  # Use the class with highest probability.\n",
    "            correct += int((pred == data.y).sum())  # Check against ground-truth labels.\n",
    "            true_labels += data.y.tolist()\n",
    "            pred_labels += pred.tolist()\n",
    "        return f1_score(true_labels, pred_labels, average='macro')\n",
    "\n",
    "    for epoch in range(0, n_epoch):\n",
    "        train()\n",
    "        train_acc = test(train_loader)\n",
    "        test_acc = test(test_loader)\n",
    "        if epoch % 1 == 0:\n",
    "            print(f'Epoch: {epoch:03d}, Train F1: {train_acc:.4f}, Test F1: {test_acc:.4f}')\n",
    "    \n",
    "    model.eval()\n",
    "    dim_vec = torch.empty((0, n_hidden_channels), dtype=torch.float32)\n",
    "    for data in all_data_loader:\n",
    "        dim_x = model.dimReduce(data.x, data.edge_index, data.batch)\n",
    "        dim_vec = torch.cat((dim_vec, dim_x), 0)\n",
    "    return (dim_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3201ea-2ee2-40ca-8d89-8dfbf13896d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_data_loader = DataLoader(dataset, batch_size=1, shuffle=False)\n",
    "dim_vec = train_model(all_data_loader, train_loader, test_loader)\n",
    "# model.eval()\n",
    "# dim_vec = torch.empty((0, n_hidden_channels), dtype=torch.float32)\n",
    "# # data = next(iter(test_loader))\n",
    "# for data in all_data_loader:\n",
    "#     dim_x = model.dimReduce(data.x, data.edge_index, data.batch)\n",
    "#     dim_vec = torch.cat((dim_vec, dim_x), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d73d8c8-fbb4-4aad-86de-173e4a05532e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# concatGNN = np.concatenate((np.array(phish_url_vectorizer), dim_vec.detach().numpy()),axis=1)\n",
    "# model_lgb = lgb.LGBMClassifier(verbose=-1)\n",
    "# model_lgb.fit(concatGNN[train_idx], labels[train_idx])\n",
    "# y_predict=model_lgb.predict(concatGNN[test_idx]) \n",
    "# print(f1_score(y_predict, labels[test_idx], average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b8358b-0dd5-4200-90a6-3354ba9a4543",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_lgb = lgb.LGBMClassifier(verbose=-1)\n",
    "# graph_embedding = dim_vec.detach().numpy()\n",
    "# model_lgb.fit(graph_embedding[train_idx], labels[train_idx])\n",
    "# y_predict=model_lgb.predict(graph_embedding[test_idx]) \n",
    "# print(f1_score(y_predict, labels[test_idx], average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1876a8-77f4-4055-8132-db0c6a1a3a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stats graph feature\n",
    "idx, vec = results[0]; vec = np.array(vec); n_features_counter = int(vec.shape[1]);\n",
    "hyperlink_features = np.zeros((smalldata.shape[0], 3*n_features_counter))\n",
    "for idx, hyper_np in results:\n",
    "    # print(idx, hyper_np)\n",
    "    hyper_np = np.array(hyper_np)\n",
    "    if hyper_np.shape[0] >= 2:\n",
    "        hyperlink_features[idx, :] = np.hstack((hyper_np.min(axis=0),hyper_np.max(axis=0), hyper_np.mean(axis=0)))\n",
    "    # hyperlink_features[idx, :] = hyper_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1469d86b-66ca-4b2b-9ceb-b6c7563658aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "concatGNN_graph = np.concatenate((np.array(phish_url_vectorizer), hyperlink_features),axis=1)\n",
    "# concatGNN_graph = np.concatenate((np.array(phish_url_vectorizer), hyperlink_features,  dim_vec.detach().numpy()),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f26d260-c6b8-4c0d-bbe3-c633b4f4c618",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lgb2 = lgb.LGBMClassifier(verbose=-1)\n",
    "model_lgb2.fit(concatGNN_graph[train_idx], labels[train_idx])\n",
    "y_predict=model_lgb2.predict(concatGNN_graph[test_idx]) \n",
    "print(f1_score(y_predict, labels[test_idx], average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894aaa75-3eb0-42d0-8cc1-273d5692a643",
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_GNNs_graph = np.concatenate((np.array(phish_url_vectorizer), hyperlink_features),axis=1)\n",
    "for i in range(10):\n",
    "    np.random.seed(i) \n",
    "    # train_idx_new = list(np.random.choice(list(range(n_samples)), int(0.8*n_samples), replace=False))\n",
    "    # train_idx_new = list(set(train_idx_new).difference(test_idx))\n",
    "    train_idx_new = list(np.random.choice(train_idx, int(0.8*len(train_idx)), replace=False))\n",
    "    print(train_idx_new[:5])\n",
    "    train_dataset_new = [dataset[idx] for idx in train_idx_new]\n",
    "    train_loader_new = DataLoader(train_dataset_new, batch_size=8, shuffle=True)\n",
    "    n_hidden_channels = 5\n",
    "    n_epoch = 1\n",
    "    dim_vec_new = train_model(all_data_loader, train_loader_new, test_loader, n_hidden_channels, n_epoch)\n",
    "    stack_GNNs_graph = np.concatenate((stack_GNNs_graph, dim_vec_new.detach().numpy()),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d2d6b21-8c3d-4dd6-9ef6-22dc9c4f473d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lgb2 = lgb.LGBMClassifier(verbose=-1)\n",
    "model_lgb2.fit(stack_GNNs_graph[train_idx], labels[train_idx])\n",
    "y_predict=model_lgb2.predict(stack_GNNs_graph[test_idx]) \n",
    "print(f1_score(y_predict, labels[test_idx], average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b023b9-429f-4145-9938-4baab04f64b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9",
   "language": "python",
   "name": "py39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
