{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2aa5aa57-71e8-4855-a10c-03cb2bb4adea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45256db8-5f10-47f7-ab3d-aab6fdc34a58",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install --upgrade numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27eb25f1-dbc1-4bfc-9deb-da49f7c72c35",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from utils import run_ML\n",
    "from sklearn.metrics import f1_score\n",
    "from itertools import groupby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5ac7c73-a600-48e9-8931-3afa1679e506",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install tldextract\n",
    "# !pip install torch_geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f4b90b7a-8d1a-4472-889c-bc87ef4a9706",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_dir = \"data/URLdatasetX2_1.csv\"\n",
    "df = pd.read_csv(data_dir,index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de4c208e-0060-4bd7-81c9-f013a1b0fdec",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2802, 2),\n",
       "                                           url        type\n",
       " 0       http://www.crestonwood.com/router.php  legitimate\n",
       " 1  http://vamoaestudiarmedicina.blogspot.com/  legitimate)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape, df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8cde64b2-2039-4c86-9c75-dffd2289622e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# smalldata = df.sample(n = 20000, random_state=1)\n",
    "# smalldata = df.sample(n = 300, random_state=1) # take random 300 samples\n",
    "smalldata = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "40045bbf-06bf-491e-8363-633d44c31be6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get labels of urls\n",
    "labels = smalldata.iloc[:,-1].values\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "labels = label_encoder.fit_transform(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa0a837d-63e3-40cf-afc9-9593072d34e4",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Conventional Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3cd8d0e0-af10-42b5-9bd9-bced95415a22",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils import extract_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "155e525e-f2fc-49d2-8be2-3b64ea9b67b4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'domain': 'www.example.com', 'num_subdomains': 2, 'contains_ip': 0, 'path_length': 20, 'num_path_segments': 3, 'uses_https': 0, 'file_extension': 'html', 'count_special_characters': 11, 'count_non_alphanumeric_characters': 11, 'TLD': 'com', 'count_obfuscated_characters': 0, 'letter_ratio_in_url': 0.7380952380952381, 'digit_ratio_in_url': 0.0, 'count_equals_in_url': 2, 'NoOfAmpersandInURL': 0, 'CharContinuationRate': 0.11904761904761904, 'ratio_obfuscated_characters': 0.0, 'NoOfQMarkInURL': 0}\n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "url = \"http://www.example.com/path/to/==file.html\"\n",
    "url_features = extract_features(url)\n",
    "print(url_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2377259d-5b19-4f0f-8758-96b1b330d117",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print(url_features.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "66cae4c3-a178-435c-9830-a4f5fd8fdc06",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get numerical and catergorical features\n",
    "phish_url = []\n",
    "for link in list(smalldata.iloc[:,0]):\n",
    "    url_features = extract_features(link)\n",
    "    phish_url.append(list(url_features.values())[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "664a11ec-0a42-4a01-91f2-208aa5796b64",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "phish_url_df = pd.DataFrame(phish_url, columns = list(url_features.keys())[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "383162e7-d058-471e-b921-d2e983efe066",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# phish_url_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aabba33a-d06a-4a3f-b021-ff8cbde0088c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "phish_url_df.iloc[:,5] = pd.Categorical(phish_url_df.iloc[:,5]).codes\n",
    "phish_url_df.iloc[:,8] = pd.Categorical(phish_url_df.iloc[:,8]).codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1cc59152-00c2-41ec-acf5-afeae474f39e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_subdomains</th>\n",
       "      <th>contains_ip</th>\n",
       "      <th>path_length</th>\n",
       "      <th>num_path_segments</th>\n",
       "      <th>uses_https</th>\n",
       "      <th>file_extension</th>\n",
       "      <th>count_special_characters</th>\n",
       "      <th>count_non_alphanumeric_characters</th>\n",
       "      <th>TLD</th>\n",
       "      <th>count_obfuscated_characters</th>\n",
       "      <th>letter_ratio_in_url</th>\n",
       "      <th>digit_ratio_in_url</th>\n",
       "      <th>count_equals_in_url</th>\n",
       "      <th>NoOfAmpersandInURL</th>\n",
       "      <th>CharContinuationRate</th>\n",
       "      <th>ratio_obfuscated_characters</th>\n",
       "      <th>NoOfQMarkInURL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>0.810811</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.135135</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   num_subdomains  contains_ip  path_length  num_path_segments  uses_https  \\\n",
       "0               2            0           11                  1           0   \n",
       "1               2            0            1                  1           0   \n",
       "\n",
       "  file_extension  count_special_characters  count_non_alphanumeric_characters  \\\n",
       "0             47                         7                                  7   \n",
       "1              0                         6                                  6   \n",
       "\n",
       "  TLD  count_obfuscated_characters  letter_ratio_in_url  digit_ratio_in_url  \\\n",
       "0  38                            0             0.810811                 0.0   \n",
       "1  38                            0             0.857143                 0.0   \n",
       "\n",
       "   count_equals_in_url  NoOfAmpersandInURL  CharContinuationRate  \\\n",
       "0                    0                   0              0.135135   \n",
       "1                    0                   0              0.047619   \n",
       "\n",
       "   ratio_obfuscated_characters  NoOfQMarkInURL  \n",
       "0                          0.0               0  \n",
       "1                          0.0               0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phish_url_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "503ed86a-9489-487f-8054-8c0d4653da36",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run:  0 , fold:  0\n",
      "Train freq:  [1630, 611]\n",
      "kNN, LightGBM, Run:  0 , fold:  1\n",
      "Train freq:  [1617, 624]\n",
      "kNN, LightGBM, Run:  0 , fold:  2\n",
      "Train freq:  [1602, 640]\n",
      "kNN, LightGBM, Run:  0 , fold:  3\n",
      "Train freq:  [1645, 597]\n",
      "kNN, LightGBM, Run:  0 , fold:  4\n",
      "Train freq:  [1622, 620]\n",
      "kNN, LightGBM, ['kNN', 'LightGBM']\n",
      "[0.73 0.86]\n"
     ]
    }
   ],
   "source": [
    "# test on URLs features\n",
    "run_ML(phish_url_df, labels, \"URLdatasetX2\", \"manual\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c999c69c-2338-4ea3-a5df-2bbd10c0dd49",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run:  0 , fold:  0\n",
      "Train freq:  [1630, 611]\n",
      "kNN, LightGBM, Run:  0 , fold:  1\n",
      "Train freq:  [1617, 624]\n",
      "kNN, LightGBM, Run:  0 , fold:  2\n",
      "Train freq:  [1602, 640]\n",
      "kNN, LightGBM, Run:  0 , fold:  3\n",
      "Train freq:  [1645, 597]\n",
      "kNN, LightGBM, Run:  0 , fold:  4\n",
      "Train freq:  [1622, 620]\n",
      "kNN, LightGBM, ['kNN', 'LightGBM']\n",
      "[0.73 0.83]\n"
     ]
    }
   ],
   "source": [
    "## test on numerical URLs features\n",
    "from utils import extract_numerical_features\n",
    "phish_url = []\n",
    "for link in list(smalldata.iloc[:,0]):\n",
    "    url_features = extract_numerical_features(link)\n",
    "    phish_url.append(list(url_features.values()))\n",
    "run_ML(np.array(phish_url), labels, \"URLdatasetX2\", \"manual_numerical\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2f45c022-60fb-4a87-9b53-10f2a093f7fc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8240798811685096\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "n_samples = len(smalldata.index)\n",
    "train_idx = list(np.random.choice(list(range(n_samples)), int(0.8*n_samples), replace=False))\n",
    "test_idx = list(set(list(range(n_samples))).difference(set(train_idx)))\n",
    "data_df = np.array(phish_url)\n",
    "import lightgbm as lgb\n",
    "model = lgb.LGBMClassifier(verbose=-1)\n",
    "model.fit(data_df[train_idx], labels[train_idx])\n",
    "y_predict=model.predict(data_df[test_idx]) \n",
    "print(f1_score(y_predict, labels[test_idx], average='macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "695c2e9e-0c05-4e9d-8abe-d89cf1519c87",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Graph NMF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef79b7fe-f017-4894-a558-ecf95e00c992",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Extract graph features from URLs for PyG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "41e1310b-4dbf-4d02-9bff-bd239f122c99",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from requests.exceptions import ConnectionError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "915bbff4-e3dd-41c1-ab35-521e6157ab38",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# return root and hyperlinks features\n",
    "def get_graph_features(idx):\n",
    "    url = smalldata.iloc[idx,0]\n",
    "    root_feature = extract_numerical_features(url) # dict\n",
    "    hyperlink_data = [list(root_feature.values())]\n",
    "    try:    \n",
    "        # find all hyperlinks\n",
    "        reqs = requests.get(url)\n",
    "        soup = BeautifulSoup(reqs.text, 'html.parser')\n",
    "        urls = []\n",
    "        count = 0;\n",
    "        for link in soup.find_all('a'):\n",
    "            # print(link.get('href'))\n",
    "            weblink = link.get('href')\n",
    "            if (weblink is not None) and ('http' in weblink):\n",
    "                urls.append(weblink)\n",
    "            count += 1\n",
    "            if count > 50:\n",
    "                break\n",
    "        # extract numerical features in from hyperlinks\n",
    "        if len(urls) > 0:\n",
    "            for link in urls:\n",
    "                try:\n",
    "                    url_features = extract_numerical_features(link)\n",
    "                    datalinkssss = list(url_features.values())\n",
    "                except ValueError as ve:\n",
    "                    # datalinkssss = list(np.zeros(15))#raw_graph_features\n",
    "                    error_here = 1;\n",
    "                hyperlink_data.append(datalinkssss)\n",
    "        else:\n",
    "            # hyperlink_data.append(list(np.zeros(15)))#raw_graph_features\n",
    "            error_here = 1;\n",
    "    \n",
    "    except ConnectionError as e:\n",
    "        # print(\"No rep\", end = ',')\n",
    "        # hyperlink_data.append(list(np.zeros(15))) #raw_graph_features\n",
    "        error_here = 1; #v2\n",
    "    return (idx,  hyperlink_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "88edc638-0997-402c-b8b1-16946d1365bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# n_test_samples = int(df.shape[0]) # how many link we want to test\n",
    "# from joblib import Parallel, delayed\n",
    "# results = Parallel(n_jobs=8)(delayed(get_graph_features)(i) for i in range(n_test_samples)) # test on 100 links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ce15f489-a148-40cd-95f9-46ba0d8a3acd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "data_file = \"data/raw_graph_features_v2.pickle\"\n",
    "# with open(data_file, \"wb\") as fp:   #Pickling\n",
    "#     pickle.dump(results, fp)\n",
    "with open(data_file, \"rb\") as fp:   # Unpickling\n",
    "     results = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "de7c7cb3-8264-4e63-bd9f-0f66d808387c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[855, 615, 70, 352, 118, 124, 1620, 298, 1992, 2262]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_samples = len(df.index)\n",
    "np.random.seed(0)\n",
    "train_idx = list(np.random.choice(list(range(n_samples)), int(0.8*n_samples), replace=False))\n",
    "test_idx = list(set(list(range(n_samples))).difference(set(train_idx)))\n",
    "train_idx[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "df29150c-55b0-43d4-b0e9-05c8e91b2ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import NMF\n",
    "n_components = 10\n",
    "nmf = NMF(\n",
    "    n_components=n_components,\n",
    "    random_state=1,\n",
    "    init='random',\n",
    "    beta_loss=\"kullback-leibler\",\n",
    "    alpha_W=0.00005,\n",
    "    alpha_H=0.005,\n",
    "    l1_ratio=1,\n",
    "    solver = 'mu',\n",
    "    max_iter = 5000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b68ca2d8-3ee9-4042-9073-5b4a2670930f",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_NMF_data = np.zeros((n_samples, 3*n_components))\n",
    "for i in range(len(results)):\n",
    "    idx, graph_feature = results[i]\n",
    "    if len(graph_feature) >= n_components:\n",
    "        data_ = np.array(graph_feature)\n",
    "        W = nmf.fit_transform(data_)\n",
    "        # graph_NMF_data[idx, :] = np.hstack((W.min(axis=0), W.max(axis=0), W.mean(axis=0))) # 0.85-0.87\n",
    "        graph_NMF_data[idx, :] = np.hstack((W.min(axis=0), W.max(axis=0), W.mean(axis=0))) # 0.85-0.87\n",
    "\n",
    "# ## PCA\n",
    "# from sklearn.decomposition import PCA\n",
    "# pca = PCA(n_components=n_components)\n",
    "# graph_NMF_data = np.zeros((n_samples, 3*n_components))\n",
    "# for i in range(len(results)):\n",
    "#     idx, graph_feature = results[i]\n",
    "#     if len(graph_feature) >= n_components:\n",
    "#         data_ = np.array(graph_feature)\n",
    "#         W = pca.fit_transform(data_)\n",
    "#         graph_NMF_data[idx, :] = np.hstack((W.min(axis=0), W.max(axis=0), W.mean(axis=0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ee049ab9-be06-4063-94e5-fbc5853d972d",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_nmf_concat = np.concatenate((data_df, graph_NMF_data),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4ad10c38-0eee-4702-b2b8-85d6b553b3aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8498746382211391\n"
     ]
    }
   ],
   "source": [
    "# Approach 1\n",
    "import lightgbm as lgb\n",
    "model = lgb.LGBMClassifier(verbose=-1)\n",
    "model.fit(graph_nmf_concat[train_idx], labels[train_idx])\n",
    "y_predict=model.predict(graph_nmf_concat[test_idx]) \n",
    "print(f1_score(y_predict, labels[test_idx], average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2c2acef6-6f51-4e92-a118-891f9018dfac",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_data = np.zeros((n_samples, 15*3))\n",
    "for i in range(len(results)):\n",
    "    idx, graph_feature = results[i]\n",
    "    if len(graph_feature) > 1:\n",
    "        data_ = np.array(graph_feature[1:])\n",
    "        graph_data[idx, :] = np.hstack((data_.min(axis=0), data_.max(axis=0), data_.mean(axis=0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "41f9eee2-b61e-43ea-9d40-6f8b4418f4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_concat = np.concatenate((data_df, graph_data),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "265780c5-3013-4203-96ff-25bd2811d08f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8629210920701114\n"
     ]
    }
   ],
   "source": [
    "model = lgb.LGBMClassifier(verbose=-1)\n",
    "model.fit(graph_concat[train_idx], labels[train_idx])\n",
    "y_predict=model.predict(graph_concat[test_idx]) \n",
    "print(f1_score(y_predict, labels[test_idx], average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "96802a11-9540-45d1-85d4-b0b553f1e45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_concat_3 = np.concatenate((data_df, graph_data, graph_nmf_concat),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ba7b3552-f22b-4ae1-8dfa-acd77951a1a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8700528696302376\n"
     ]
    }
   ],
   "source": [
    "# Approach 2\n",
    "model = lgb.LGBMClassifier(verbose=-1)\n",
    "model.fit(graph_concat_3[train_idx], labels[train_idx])\n",
    "y_predict=model.predict(graph_concat_3[test_idx]) \n",
    "print(f1_score(y_predict, labels[test_idx], average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e7c1a504-a86d-44ea-ae68-52f09b83f885",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Graph autoencoder for every graph then concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "38e81c8c-80e4-4d17-953f-7f7c5e6f6c0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Names (N-grams): ['!' '!t' '!to' ... '~mr' '~mri' '~mric']\n",
      "TF-IDF Matrix:\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer\n",
    "\n",
    "# List of URLs\n",
    "urls = list(smalldata['url'])\n",
    "\n",
    "# Tokenization and N-grams Generation\n",
    "# You can adjust ngram_range to extract different n-grams (e.g., (1, 1) for unigrams, (2, 2) for bigrams, etc.)\n",
    "vectorizer = CountVectorizer(analyzer='char', ngram_range=(1, 5))\n",
    "X_counts = vectorizer.fit_transform(urls)\n",
    "\n",
    "# TF-IDF Transformation\n",
    "transformer = TfidfTransformer()\n",
    "X_tfidf = transformer.fit_transform(X_counts)\n",
    "\n",
    "# Extracted Features\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "print(\"Feature Names (N-grams):\", feature_names)\n",
    "print(\"TF-IDF Matrix:\")\n",
    "X_tfidf_data = X_tfidf.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "225149d8-9b50-4971-88f7-f42322611b8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2802, 123908)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tfidf_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3f18ad94-dd3b-45e4-888e-420439eab526",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run:  0 , fold:  0\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 2.07 GiB for an array with shape (2241, 123908) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[41], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mrun_ML\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_tfidf_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mURLdatasetX2\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtfIDF\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\server\\URLPhishing\\utils.py:56\u001b[0m, in \u001b[0;36mrun_ML\u001b[1;34m(X, y, data_set, approach)\u001b[0m\n\u001b[0;32m     54\u001b[0m path_dir \u001b[38;5;241m=\u001b[39m base_dir \u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m data_set \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_run_\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(i)\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfold_\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(fold)\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39mapproach\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRun: \u001b[39m\u001b[38;5;124m'\u001b[39m, i, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, fold: \u001b[39m\u001b[38;5;124m'\u001b[39m, fold)\n\u001b[1;32m---> 56\u001b[0m X_train \u001b[38;5;241m=\u001b[39m \u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtrain_idx\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     57\u001b[0m X_test \u001b[38;5;241m=\u001b[39m X[test_idx]\n\u001b[0;32m     58\u001b[0m y_train \u001b[38;5;241m=\u001b[39m y[train_idx]\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 2.07 GiB for an array with shape (2241, 123908) and data type float64"
     ]
    }
   ],
   "source": [
    "run_ML(X_tfidf_data, labels, \"URLdatasetX2\", \"tfIDF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d1ba0a-07e4-47ac-a843-cb30f0930254",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9",
   "language": "python",
   "name": "py39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
