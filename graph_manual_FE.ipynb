{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51996577-859a-466e-a40f-b60f6a51a8d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# Combine graph features and use standard algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "27eb25f1-dbc1-4bfc-9deb-da49f7c72c35",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from utils import run_ML\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5ac7c73-a600-48e9-8931-3afa1679e506",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install tldextract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4b90b7a-8d1a-4472-889c-bc87ef4a9706",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_dir = \"data/URLdatasetX2_1.csv\"\n",
    "df = pd.read_csv(data_dir,index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de4c208e-0060-4bd7-81c9-f013a1b0fdec",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2802, 2),\n",
       "                                           url        type\n",
       " 0       http://www.crestonwood.com/router.php  legitimate\n",
       " 1  http://vamoaestudiarmedicina.blogspot.com/  legitimate)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape, df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8cde64b2-2039-4c86-9c75-dffd2289622e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# smalldata = df.sample(n = 20000, random_state=1)\n",
    "smalldata = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "40045bbf-06bf-491e-8363-633d44c31be6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if 'PhiUSIIL' in data_dir:\n",
    "    urldata = np.array(smalldata[['URLLength', 'DomainLength', 'IsDomainIP', \\\n",
    "           'URLSimilarityIndex', 'CharContinuationRate', 'TLDLegitimateProb',\\\n",
    "           'URLCharProb', 'TLDLength', 'NoOfSubDomain', 'HasObfuscation',\\\n",
    "           'NoOfObfuscatedChar', 'ObfuscationRatio', 'NoOfLettersInURL',\\\n",
    "           'LetterRatioInURL', 'NoOfDegitsInURL', 'DegitRatioInURL',\\\n",
    "           'NoOfEqualsInURL', 'NoOfQMarkInURL', 'NoOfAmpersandInURL',\\\n",
    "           'NoOfOtherSpecialCharsInURL', 'SpacialCharRatioInURL', 'IsHTTPS']])\n",
    "    labels = smalldata.iloc[:,-1].values\n",
    "    run_ML(urldata, labels, \"PhiUSIILmock\", \"standard\")\n",
    "if 'URLdatasetX2' in data_dir:\n",
    "    labels = smalldata.iloc[:,-1].values\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    label_encoder = LabelEncoder()\n",
    "    labels = label_encoder.fit_transform(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa0a837d-63e3-40cf-afc9-9593072d34e4",
   "metadata": {},
   "source": [
    "### Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3cd8d0e0-af10-42b5-9bd9-bced95415a22",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils import extract_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "155e525e-f2fc-49d2-8be2-3b64ea9b67b4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'domain': 'www.example.com', 'num_subdomains': 2, 'contains_ip': 0, 'path_length': 20, 'num_path_segments': 3, 'uses_https': 0, 'file_extension': 'html', 'count_special_characters': 11, 'count_non_alphanumeric_characters': 11, 'TLD': 'com', 'count_obfuscated_characters': 0, 'letter_ratio_in_url': 0.7380952380952381, 'digit_ratio_in_url': 0.0, 'count_equals_in_url': 2, 'NoOfAmpersandInURL': 0, 'CharContinuationRate': 0.11904761904761904, 'ratio_obfuscated_characters': 0.0, 'NoOfQMarkInURL': 0}\n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "url = \"http://www.example.com/path/to/==file.html\"\n",
    "url_features = extract_features(url)\n",
    "print(url_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2377259d-5b19-4f0f-8758-96b1b330d117",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print(url_features.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "66cae4c3-a178-435c-9830-a4f5fd8fdc06",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "phish_url = []\n",
    "for link in list(smalldata.iloc[:,0]):\n",
    "    url_features = extract_features(link)\n",
    "    phish_url.append(list(url_features.values())[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "664a11ec-0a42-4a01-91f2-208aa5796b64",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "phish_url_df = pd.DataFrame(phish_url, columns = list(url_features.keys())[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "383162e7-d058-471e-b921-d2e983efe066",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# phish_url_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "aabba33a-d06a-4a3f-b021-ff8cbde0088c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "phish_url_df.iloc[:,5] = pd.Categorical(phish_url_df.iloc[:,5]).codes\n",
    "phish_url_df.iloc[:,8] = pd.Categorical(phish_url_df.iloc[:,8]).codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1cc59152-00c2-41ec-acf5-afeae474f39e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_subdomains</th>\n",
       "      <th>contains_ip</th>\n",
       "      <th>path_length</th>\n",
       "      <th>num_path_segments</th>\n",
       "      <th>uses_https</th>\n",
       "      <th>file_extension</th>\n",
       "      <th>count_special_characters</th>\n",
       "      <th>count_non_alphanumeric_characters</th>\n",
       "      <th>TLD</th>\n",
       "      <th>count_obfuscated_characters</th>\n",
       "      <th>letter_ratio_in_url</th>\n",
       "      <th>digit_ratio_in_url</th>\n",
       "      <th>count_equals_in_url</th>\n",
       "      <th>NoOfAmpersandInURL</th>\n",
       "      <th>CharContinuationRate</th>\n",
       "      <th>ratio_obfuscated_characters</th>\n",
       "      <th>NoOfQMarkInURL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>0.810811</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.135135</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   num_subdomains  contains_ip  path_length  num_path_segments  uses_https  \\\n",
       "0               2            0           11                  1           0   \n",
       "1               2            0            1                  1           0   \n",
       "\n",
       "   file_extension  count_special_characters  \\\n",
       "0              47                         7   \n",
       "1               0                         6   \n",
       "\n",
       "   count_non_alphanumeric_characters  TLD  count_obfuscated_characters  \\\n",
       "0                                  7   38                            0   \n",
       "1                                  6   38                            0   \n",
       "\n",
       "   letter_ratio_in_url  digit_ratio_in_url  count_equals_in_url  \\\n",
       "0             0.810811                 0.0                    0   \n",
       "1             0.857143                 0.0                    0   \n",
       "\n",
       "   NoOfAmpersandInURL  CharContinuationRate  ratio_obfuscated_characters  \\\n",
       "0                   0              0.135135                          0.0   \n",
       "1                   0              0.047619                          0.0   \n",
       "\n",
       "   NoOfQMarkInURL  \n",
       "0               0  \n",
       "1               0  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phish_url_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "503ed86a-9489-487f-8054-8c0d4653da36",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run:  0 , fold:  0\n",
      "Train freq:  [1630, 611]\n",
      "kNN, LightGBM, Run:  0 , fold:  1\n",
      "Train freq:  [1617, 624]\n",
      "kNN, LightGBM, Run:  0 , fold:  2\n",
      "Train freq:  [1602, 640]\n",
      "kNN, LightGBM, Run:  0 , fold:  3\n",
      "Train freq:  [1645, 597]\n",
      "kNN, LightGBM, Run:  0 , fold:  4\n",
      "Train freq:  [1622, 620]\n",
      "kNN, LightGBM, ['kNN', 'LightGBM']\n",
      "[0.73 0.86]\n"
     ]
    }
   ],
   "source": [
    "run_ML(phish_url_df, labels, \"URLdatasetX2\", \"manual\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "32a1c51d-a596-43bf-a2db-0385d1f82953",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run:  0 , fold:  0\n",
      "Train freq:  [1630, 611]\n",
      "kNN, LightGBM, Run:  0 , fold:  1\n",
      "Train freq:  [1617, 624]\n",
      "kNN, LightGBM, Run:  0 , fold:  2\n",
      "Train freq:  [1602, 640]\n",
      "kNN, LightGBM, Run:  0 , fold:  3\n",
      "Train freq:  [1645, 597]\n",
      "kNN, LightGBM, Run:  0 , fold:  4\n",
      "Train freq:  [1622, 620]\n",
      "kNN, LightGBM, ['kNN', 'LightGBM']\n",
      "[0.73 0.83]\n"
     ]
    }
   ],
   "source": [
    "## Numerical features\n",
    "from utils import extract_numerical_features\n",
    "phish_url = []\n",
    "for link in list(smalldata.iloc[:,0]):\n",
    "    url_features = extract_numerical_features(link)\n",
    "    phish_url.append(list(url_features.values()))\n",
    "run_ML(np.array(phish_url), labels, \"URLdatasetX2\", \"manual_numerical\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a7e487d3-e9c3-4b34-b4d7-c6347e1bf8a2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from requests.exceptions import ConnectionError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d6b4d391-17e2-44a1-a890-0685ba9d5d11",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# hyperlink_features = np.zeros((smalldata.shape[0], 48))\n",
    "# enum = 0;\n",
    "# for url in list(smalldata.iloc[:,0]):\n",
    "#     # url = 'https://polarklimatsgserver.blogspot.com/'\n",
    "#     try:    \n",
    "#         reqs = requests.get(url)\n",
    "#         soup = BeautifulSoup(reqs.text, 'html.parser')\n",
    "#         urls = []\n",
    "#         count = 0;\n",
    "#         for link in soup.find_all('a'):\n",
    "#             # print(link.get('href'))\n",
    "#             weblink = link.get('href')\n",
    "#             if (weblink is not None) and ('http' in weblink):\n",
    "#                 urls.append(weblink)\n",
    "#             count += 1\n",
    "#             if count > 50:\n",
    "#                 break\n",
    "#         # extract numerical features in link\n",
    "#         if len(urls) > 0:\n",
    "#             hyperlink_data = []\n",
    "#             for link in urls:\n",
    "#                 try:\n",
    "#                     url_features = extract_numerical_features(link)\n",
    "#                     datalinkssss = list(url_features.values())\n",
    "#                 except ValueError as ve:\n",
    "#                     datalinkssss = list(np.zeros(15))\n",
    "#                 hyperlink_data.append(datalinkssss)\n",
    "#             hyperlink_data = np.array(hyperlink_data)\n",
    "#             hyper_np = np.hstack((np.array([len(urls), count, float(len(urls))/(count + 1)]),\n",
    "#                                   hyperlink_data.min(axis=0),hyperlink_data.max(axis=0), hyperlink_data.mean(axis=0)))\n",
    "#         else:\n",
    "#             hyper_np = np.hstack((np.array([len(urls), count, float(len(urls))/(count + 1)]),np.zeros(45)))\n",
    "    \n",
    "#     except ConnectionError as e:\n",
    "#         print(\"No rep\", end = ',')\n",
    "#         hyper_np = np.zeros(48)\n",
    "#     hyperlink_features[enum, :] = hyper_np\n",
    "#     print(enum, end =',')\n",
    "#     enum += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "915bbff4-e3dd-41c1-ab35-521e6157ab38",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for url in list(smalldata.iloc[:,0]):\n",
    "def get_features(idx):\n",
    "    url = smalldata.iloc[idx,0]\n",
    "    # url = 'https://polarklimatsgserver.blogspot.com/'\n",
    "    try:    \n",
    "        reqs = requests.get(url)\n",
    "        soup = BeautifulSoup(reqs.text, 'html.parser')\n",
    "        urls = []\n",
    "        count = 0;\n",
    "        for link in soup.find_all('a'):\n",
    "            # print(link.get('href'))\n",
    "            weblink = link.get('href')\n",
    "            if (weblink is not None) and ('http' in weblink):\n",
    "                urls.append(weblink)\n",
    "            count += 1\n",
    "            if count > 50:\n",
    "                break\n",
    "        # extract numerical features in link\n",
    "        if len(urls) > 0:\n",
    "            hyperlink_data = []\n",
    "            for link in urls:\n",
    "                try:\n",
    "                    url_features = extract_numerical_features(link)\n",
    "                    datalinkssss = list(url_features.values())\n",
    "                except ValueError as ve:\n",
    "                    datalinkssss = list(np.zeros(15))\n",
    "                hyperlink_data.append(datalinkssss)\n",
    "            hyperlink_data = np.array(hyperlink_data)\n",
    "            hyper_np = np.hstack((np.array([len(urls), count, float(len(urls))/(count + 1)]),\n",
    "                                  hyperlink_data.min(axis=0),hyperlink_data.max(axis=0), hyperlink_data.mean(axis=0)))\n",
    "        else:\n",
    "            hyper_np = np.hstack((np.array([len(urls), count, float(len(urls))/(count + 1)]),np.zeros(45)))\n",
    "    \n",
    "    except ConnectionError as e:\n",
    "        # print(\"No rep\", end = ',')\n",
    "        hyper_np = np.zeros(48)\n",
    "    # hyperlink_features[enum, :] = hyper_np\n",
    "    # print(enum, end =',')\n",
    "    # enum += 1\n",
    "    return (idx, hyper_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b9e04b97-0ccf-47a0-8dfa-4917ab68e4de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "results = Parallel(n_jobs=32)(delayed(get_features)(i) for i in range(len(smalldata.index)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5b042ebe-80ff-48a6-98c4-61413b5b0a29",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hyperlink_features = np.zeros((smalldata.shape[0], 48))\n",
    "for idx, hyper_np in results:\n",
    "    # print(idx, hyper_np)\n",
    "    hyperlink_features[idx, :] = hyper_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b61eb313-8a1c-4420-9691-0355fab3d802",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# np.save('data/hyperlink_features.npy', hyperlink_features) # save\n",
    "# np.save('data/phish_url_df.npy', phish_url_df.to_numpy()) # save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "aa88fabb-b174-461e-a50d-fb5ec2bf9a33",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run:  0 , fold:  0\n",
      "Train freq:  [1630, 611]\n",
      "kNN, LightGBM, Run:  0 , fold:  1\n",
      "Train freq:  [1617, 624]\n",
      "kNN, LightGBM, Run:  0 , fold:  2\n",
      "Train freq:  [1602, 640]\n",
      "kNN, LightGBM, Run:  0 , fold:  3\n",
      "Train freq:  [1645, 597]\n",
      "kNN, LightGBM, Run:  0 , fold:  4\n",
      "Train freq:  [1622, 620]\n",
      "kNN, LightGBM, ['kNN', 'LightGBM']\n",
      "[0.81 0.92]\n"
     ]
    }
   ],
   "source": [
    "run_ML(np.concatenate((phish_url_df.to_numpy(), hyperlink_features),axis=1), labels, \"URLdatasetX2\", \"hyperlinks_features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7266b5e2-6bcc-4663-9207-e7648ad038b1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9031924072476273\n"
     ]
    }
   ],
   "source": [
    "n_samples = len(smalldata.index)\n",
    "np.random.seed(0)\n",
    "train_idx = list(np.random.choice(list(range(n_samples)), int(0.8*n_samples), replace=False))\n",
    "test_idx = list(set(list(range(n_samples))).difference(set(train_idx)))\n",
    "data_df = np.concatenate((phish_url_df.to_numpy(), hyperlink_features),axis=1)\n",
    "import lightgbm as lgb\n",
    "model = lgb.LGBMClassifier(verbose=-1)\n",
    "model.fit(data_df[train_idx], labels[train_idx])\n",
    "y_predict=model.predict(data_df[test_idx]) \n",
    "print(f1_score(y_predict, labels[test_idx], average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b4358a-21ff-4898-b519-5561fd7d97ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python py38",
   "language": "python",
   "name": "py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
